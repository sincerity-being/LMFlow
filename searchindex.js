Search.setIndex({"docnames": ["about/authors", "about/changelog", "about/index", "api/_autosummary/lmflow.args", "autoapi/index", "autoapi/lmflow/args/index", "autoapi/lmflow/datasets/dataset/index", "autoapi/lmflow/datasets/index", "autoapi/lmflow/index", "autoapi/lmflow/models/auto_model/index", "autoapi/lmflow/models/base_model/index", "autoapi/lmflow/models/decoder_model/index", "autoapi/lmflow/models/encoder_decoder_model/index", "autoapi/lmflow/models/hf_decoder_model/index", "autoapi/lmflow/models/hf_encoder_decoder_model/index", "autoapi/lmflow/models/index", "autoapi/lmflow/models/interfaces/index", "autoapi/lmflow/models/interfaces/tunable/index", "autoapi/lmflow/models/regression_model/index", "autoapi/lmflow/models/text_regression_model/index", "autoapi/lmflow/pipeline/auto_pipeline/index", "autoapi/lmflow/pipeline/base_aligner/index", "autoapi/lmflow/pipeline/base_pipeline/index", "autoapi/lmflow/pipeline/base_tuner/index", "autoapi/lmflow/pipeline/evaluator/index", "autoapi/lmflow/pipeline/finetuner/index", "autoapi/lmflow/pipeline/index", "autoapi/lmflow/pipeline/inferencer/index", "autoapi/lmflow/pipeline/raft_aligner/index", "autoapi/lmflow/pipeline/utils/index", "autoapi/lmflow/pipeline/utils/peft_trainer/index", "autoapi/lmflow/pipeline/utils/raft_trainer/index", "autoapi/lmflow/utils/constants/index", "autoapi/lmflow/utils/data_utils/index", "autoapi/lmflow/utils/flash_attention/gpt_neo_flash_attention/index", "autoapi/lmflow/utils/flash_attention/index", "autoapi/lmflow/utils/flash_attention/llama_flash_attention/index", "autoapi/lmflow/utils/index", "autoapi/lmflow/version/index", "blogs/benchmark", "blogs/index", "examples/DATASETS", "examples/TASK_GUIDE", "examples/checkpoints", "examples/index", "examples/medical_finetune", "examples/raft", "examples/reward_modeling", "index"], "filenames": ["about/authors.md", "about/changelog.md", "about/index.md", "api/_autosummary/lmflow.args.rst", "autoapi/index.rst", "autoapi/lmflow/args/index.rst", "autoapi/lmflow/datasets/dataset/index.rst", "autoapi/lmflow/datasets/index.rst", "autoapi/lmflow/index.rst", "autoapi/lmflow/models/auto_model/index.rst", "autoapi/lmflow/models/base_model/index.rst", "autoapi/lmflow/models/decoder_model/index.rst", "autoapi/lmflow/models/encoder_decoder_model/index.rst", "autoapi/lmflow/models/hf_decoder_model/index.rst", "autoapi/lmflow/models/hf_encoder_decoder_model/index.rst", "autoapi/lmflow/models/index.rst", "autoapi/lmflow/models/interfaces/index.rst", "autoapi/lmflow/models/interfaces/tunable/index.rst", "autoapi/lmflow/models/regression_model/index.rst", "autoapi/lmflow/models/text_regression_model/index.rst", "autoapi/lmflow/pipeline/auto_pipeline/index.rst", "autoapi/lmflow/pipeline/base_aligner/index.rst", "autoapi/lmflow/pipeline/base_pipeline/index.rst", "autoapi/lmflow/pipeline/base_tuner/index.rst", "autoapi/lmflow/pipeline/evaluator/index.rst", "autoapi/lmflow/pipeline/finetuner/index.rst", "autoapi/lmflow/pipeline/index.rst", "autoapi/lmflow/pipeline/inferencer/index.rst", "autoapi/lmflow/pipeline/raft_aligner/index.rst", "autoapi/lmflow/pipeline/utils/index.rst", "autoapi/lmflow/pipeline/utils/peft_trainer/index.rst", "autoapi/lmflow/pipeline/utils/raft_trainer/index.rst", "autoapi/lmflow/utils/constants/index.rst", "autoapi/lmflow/utils/data_utils/index.rst", "autoapi/lmflow/utils/flash_attention/gpt_neo_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/llama_flash_attention/index.rst", "autoapi/lmflow/utils/index.rst", "autoapi/lmflow/version/index.rst", "blogs/benchmark.md", "blogs/index.md", "examples/DATASETS.md", "examples/TASK_GUIDE.md", "examples/checkpoints.md", "examples/index.md", "examples/medical_finetune.md", "examples/raft.md", "examples/reward_modeling.md", "index.md"], "titles": ["Contributors", "Changelog", "About", "lmflow.args", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.args</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets.dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.auto_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.base_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.encoder_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_encoder_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces.tunable</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.text_regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.auto_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_tuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.evaluator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.finetuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.inferencer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.raft_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils.peft_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils.raft_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.data_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.gpt_neo_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.llama_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.version</span></code>", "LMFlow Benchmark: An Automatic Evaluation Framework for Open-Source LLMs", "Blogs", "Dataset", "LMFlow Benchmark Guide", "Checkpoints", "Examples", "Finetune", "1 Introduction", "Reward Modeling", "LMFlow"], "terms": {"shizh": [0, 48], "diao": [0, 48], "rui": [0, 48], "pan": [0, 48], "hanz": [0, 48], "dong": [0, 48], "ka": 0, "shun": 0, "shum": [0, 48], "jipeng": [0, 48], "zhang": [0, 48], "wei": [0, 48], "xiong": [0, 48], "tong": [0, 48], "The": [1, 5, 6, 7, 11, 12, 13, 14, 20, 24, 25, 27, 28, 30, 31, 33, 39, 41, 46, 47, 48], "first": [1, 31, 39, 42, 43, 46, 47], "public": [1, 46], "task": [1, 13, 14, 31, 39, 44, 46], "tune": [1, 13, 14, 23, 25, 30, 31, 39, 45, 46, 47], "instruct": [1, 47], "user": [1, 39, 41, 42, 46, 48], "defin": [1, 3, 5, 6, 7, 30, 31, 41], "dataset": [1, 3, 4, 5, 8, 13, 14, 19, 21, 23, 24, 25, 27, 28, 30, 31, 33, 39, 44, 45, 47, 48], "A": [1, 6, 7, 11, 12, 13, 14, 19, 21, 23, 24, 28, 30, 31, 33, 39, 46, 47], "simpl": [1, 30, 31, 39, 46, 47], "extens": [1, 46, 48], "api": [1, 39, 48], "develop": [1, 39, 46], "effici": [1, 39, 46, 48], "finetun": [1, 4, 8, 26, 39, 41, 43, 48], "lora": [1, 13, 14, 44, 47, 48], "simplifi": [1, 24, 25, 27, 28, 47, 48], "model": [1, 3, 4, 5, 8, 21, 23, 24, 25, 27, 28, 30, 31, 39, 41, 43, 44, 45, 48], "infer": [1, 5, 13, 14, 19, 24, 27, 41, 46, 48], "framework": [1, 40, 46, 47], "changelog": [2, 48], "version": [2, 3, 4, 5, 8, 39], "0": [2, 8, 13, 24, 27, 28, 31, 38, 39, 43, 46, 47, 48], "1": [2, 4, 5, 6, 7, 8, 13, 24, 31, 38, 39, 41, 44, 45, 48], "mar": 2, "28": [2, 48], "2023": [2, 39, 48], "contributor": [2, 48], "thi": [3, 4, 5, 6, 7, 11, 12, 13, 14, 28, 30, 31, 33, 39, 41, 42, 46, 47, 48], "script": [3, 5, 31, 43, 45, 46, 47], "dataclass": [3, 5], "modelargu": [3, 5, 24, 25, 27, 28, 45], "datasetargu": [3, 5, 6, 7, 24, 25, 27, 28, 45], "contain": [3, 4, 5, 6, 7, 11, 12, 24, 25, 27, 28, 30, 31, 39, 41, 46], "argument": [3, 5, 6, 7, 13, 14, 19, 24, 25, 27, 28, 30, 31, 33, 45], "us": [3, 5, 10, 11, 12, 13, 14, 17, 18, 22, 24, 30, 31, 32, 33, 39, 41, 42, 43, 44, 46, 47, 48], "train": [3, 5, 13, 14, 25, 28, 30, 31, 33, 39, 41, 42, 46, 47, 48], "It": [3, 5, 13, 14, 24, 31, 39, 46, 47, 48], "import": [3, 5, 24, 30, 31, 39, 45, 46, 48], "sever": [3, 5, 13, 14, 31, 33, 39, 41, 42, 44], "modul": 3, "includ": [3, 5, 6, 7, 31, 33, 39, 46, 47, 48], "field": [3, 5, 46, 47, 48], "from": [3, 5, 6, 7, 13, 14, 24, 30, 31, 33, 39, 43, 45, 46, 47, 48], "type": [3, 5, 6, 7, 9, 19, 31, 39, 41, 42, 46, 47], "option": [3, 5, 6, 7, 11, 12, 13, 14, 19, 25, 28, 30, 31, 36, 39, 43, 46], "require_vers": [3, 5], "transform": [3, 5, 13, 14, 30, 31, 45], "util": [3, 4, 5, 8, 26, 28, 39, 48], "model_for_causal_lm_map": [3, 5], "trainingargu": [3, 5, 30, 31], "model_config_class": [3, 5], "i": [3, 5, 13, 14, 21, 23, 24, 28, 30, 31, 39, 41, 43, 46, 47, 48], "assign": [3, 5, 46], "list": [3, 5, 13, 14, 30, 31, 33, 41, 46, 48], "config": [3, 5, 45, 47], "class": 3, "model_typ": [3, 5], "tupl": [3, 5, 30, 31, 36], "extract": [3, 5, 33], "page": [4, 39, 48], "auto": [4, 5], "gener": [4, 5, 13, 14, 18, 24, 28, 30, 31, 33, 39, 43, 44, 46, 47, 48], "document": [4, 31, 39], "lmflow": [4, 40, 44, 45, 46, 47], "interfac": [4, 8, 13, 14, 15], "tunabl": [4, 8, 13, 14, 15, 16, 23], "auto_model": [4, 8, 15], "base_model": [4, 8, 11, 12, 15, 18], "decoder_model": [4, 8, 13, 15], "encoder_decoder_model": [4, 8, 14, 15], "hf_decoder_model": [4, 8, 15], "hf_encoder_decoder_model": [4, 8, 15], "regression_model": [4, 8, 15, 19], "text_regression_model": [4, 8, 15], "pipelin": [4, 8, 41, 45, 46, 48], "peft_train": [4, 8, 26, 29], "raft_train": [4, 8, 26, 29], "auto_pipelin": [4, 8, 26, 45], "base_align": [4, 8, 26, 28], "base_pipelin": [4, 8, 21, 23, 24, 26, 27], "base_tun": [4, 8, 25, 26], "evalu": [4, 5, 8, 26, 30, 31, 40, 41, 43, 46, 47, 48], "inferenc": [4, 5, 8, 26, 41], "raft_align": [4, 8, 26, 46], "flash_attent": [4, 8, 37], "gpt_neo_flash_attent": [4, 8, 35, 37], "llama_flash_attent": [4, 8, 35, 37], "constant": [4, 8, 37], "data_util": [4, 8, 37], "arg": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23, 25, 28, 30, 31, 33, 45], "creat": [4, 6, 7, 10, 11, 12, 17, 18, 22, 24, 30, 31, 44, 46, 47, 48], "sphinx": 4, "autoapi": 4, "sourc": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 36, 38, 40, 41, 46, 48], "decor": 5, "paramet": [5, 6, 7, 13, 14, 19, 24, 25, 27, 28, 30, 31, 33, 44, 47, 48], "can": [5, 13, 14, 30, 31, 39, 41, 42, 43, 46, 47, 48], "configur": [5, 46], "model_name_or_path": [5, 42, 43, 46, 47], "str": [5, 6, 7, 13, 14, 27, 30, 31, 33, 46], "string": [5, 6, 7, 13, 14, 27, 30, 31, 33], "repres": [5, 6, 7, 13, 14, 24], "path": [5, 13, 14, 19, 31, 42, 43, 45, 46], "name": [5, 13, 14, 19, 20, 30, 31, 33, 39, 41, 42, 46], "pretrain": [5, 13, 14, 31, 39, 43, 48], "checkpoint": [5, 30, 31, 39, 44, 46], "weight": [5, 24, 48], "initi": [5, 6, 7, 13, 14, 19, 24, 25, 27, 28, 31, 45, 46], "If": [5, 30, 31, 33, 39, 42, 45, 46, 47, 48], "none": [5, 6, 7, 13, 14, 24, 28, 30, 31, 33, 34, 36, 47], "scratch": 5, "provid": [5, 10, 11, 12, 13, 14, 17, 18, 22, 24, 30, 31, 39, 41, 42, 44, 46, 47, 48], "config_overrid": 5, "default": [5, 6, 7, 13, 14, 30, 31, 33, 46], "set": [5, 13, 14, 30, 31, 33, 39, 41, 43, 44, 46, 47], "overrid": [5, 31], "when": [5, 30, 31, 39, 46, 47], "config_nam": 5, "differ": [5, 6, 7, 13, 14, 30, 31, 39, 43, 46], "tokenizer_nam": 5, "token": [5, 13, 14, 24, 28, 30, 31, 39, 45, 46, 47], "cache_dir": 5, "directori": [5, 13, 14, 24, 30, 31, 41, 46], "where": [5, 24, 39, 41, 46, 47], "download": [5, 39, 41, 42, 43, 46], "huggingfac": [5, 6, 7, 13, 14, 43, 46, 47], "co": [5, 46], "store": [5, 46], "use_fast_token": 5, "bool": [5, 31, 33, 36], "boolean": 5, "indic": [5, 39, 41], "whether": [5, 13, 14, 30, 31, 46], "fast": 5, "back": [5, 46, 47], "librari": [5, 30, 31], "model_revis": 5, "specif": [5, 39, 41, 46, 47, 48], "branch": [5, 42], "tag": [5, 31], "commit": [5, 31], "id": [5, 13, 14], "use_auth_token": 5, "run": [5, 24, 25, 28, 30, 31, 39, 41, 42, 43, 46, 47], "cli": 5, "login": 5, "necessari": [5, 31, 39], "privat": 5, "torch_dtyp": 5, "dtype": [5, 31], "load": [5, 6, 7, 13, 14, 24, 25, 27, 28, 31, 33, 43], "under": [5, 30, 31, 39, 41, 42, 48], "pass": [5, 30, 31, 39, 45, 48], "automat": [5, 9, 20, 30, 31, 40], "deriv": 5, "": [5, 30, 31, 39, 42, 45, 46, 47, 48], "use_ram_optimized_load": [5, 42], "disk": 5, "map": [5, 6, 7, 19, 45, 47], "memori": [5, 46], "enough": 5, "use_int8": 5, "int8": 5, "quantiz": 5, "lora_model_path": [5, 43], "arch_typ": 5, "use_lora": 5, "lora_r": 5, "int": [5, 13, 14, 27, 31, 33, 46, 47], "lora_alpha": 5, "lora_target_modul": 5, "lora_dropout": 5, "float": [5, 19, 24, 27, 31, 46], "save_aggregated_lora": 5, "use_flash_attent": 5, "__post_init__": 5, "languag": [5, 13, 14, 24, 25, 31, 39, 48], "dataset_path": [5, 43, 46, 47], "dataset_nam": [5, 42], "valu": [5, 30, 31, 34, 42, 46], "custom": [5, 30, 31, 41, 46, 47], "is_custom_dataset": 5, "data": [5, 6, 7, 19, 24, 25, 28, 30, 31, 33, 39, 41, 42, 43, 46, 47, 48], "fals": [5, 13, 14, 30, 31, 34, 36, 42, 46, 47], "customized_cache_dir": 5, "cach": [5, 6, 7, 30, 31], "dataset_config_nam": 5, "via": [5, 39, 46], "train_fil": 5, "input": [5, 13, 14, 19, 24, 27, 28, 30, 31, 33, 36, 39, 41, 42, 43, 47], "file": [5, 24, 31, 33, 41, 44, 45, 46, 48], "text": [5, 13, 14, 24, 25, 28, 33, 39, 41, 43, 45, 46, 47], "validation_fil": 5, "perplex": [5, 39], "max_train_sampl": 5, "an": [5, 10, 11, 12, 17, 18, 22, 30, 31, 40, 46, 47, 48], "integ": 5, "maximum": [5, 24, 25, 30, 31], "number": [5, 24, 31, 46], "exampl": [5, 11, 12, 30, 31, 33, 39, 41, 42, 43, 48], "debug": 5, "quicker": 5, "truncat": [5, 47], "max_eval_sampl": 5, "stream": 5, "enabl": 5, "mode": [5, 30, 31, 46], "block_siz": 5, "sequenc": [5, 13, 14, 31, 39], "length": [5, 13, 14, 24, 25, 30, 31, 33, 39], "after": [5, 30, 39, 42, 46], "block": [5, 25, 31], "size": [5, 24, 30, 31, 39, 46], "also": [5, 11, 12, 24, 31, 39, 42, 46, 47, 48], "some": [5, 24, 30, 31, 39, 42, 46, 47, 48], "addit": [5, 31], "further": [5, 39, 46, 48], "overwrite_cach": 5, "validation_split_percentag": [5, 46, 47], "preprocessing_num_work": 5, "disable_group_text": 5, "demo_example_in_prompt": 5, "explanation_in_prompt": 5, "keep_linebreak": 5, "prompt_structur": [5, 27, 42, 43], "function": [5, 11, 12, 19, 28, 30, 31, 46, 47, 48], "help": [5, 39, 46, 47, 48], "messag": [5, 6, 7, 31], "each": [5, 30, 31, 41, 46, 47], "hint": [5, 6, 7], "metadata": [5, 31, 46], "inform": [5, 6, 7, 24, 31, 46, 47, 48], "about": [5, 31, 39, 46, 47, 48], "group_texts_batch_s": 5, "test_fil": 5, "finetunerargu": [5, 25], "base": [5, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 39, 46, 47, 48], "adapt": [5, 13, 14, 30, 31, 46, 48], "eval_dataset_path": 5, "evaluatorargu": [5, 24], "local_rank": [5, 28], "For": [5, 30, 31, 39, 41, 44, 46, 47, 48], "distribut": [5, 30, 31], "random_shuffl": [5, 33], "use_wandb": [5, 24], "random_se": 5, "output_dir": [5, 30, 31, 43, 46], "mixed_precis": 5, "choic": [5, 33, 39, 46], "bf16": 5, "fp16": 5, "mix": [5, 46], "precis": 5, "deepspe": [5, 13, 14, 30, 31, 42, 43, 45], "json": [5, 6, 7, 31, 33, 41, 42, 43, 45, 46, 47], "e": [5, 28, 30, 31, 33, 41, 42, 46, 48], "g": [5, 30, 31, 41, 46], "ds_config": [5, 13, 14, 42, 43], "alreadi": [5, 31, 39, 46, 47], "dict": [5, 6, 7, 30, 31], "temperatur": [5, 27, 46], "control": [5, 6, 7, 30, 31], "divers": [5, 39, 46], "repetition_penalti": 5, "penal": 5, "repetit": 5, "answer_typ": [5, 24, 33, 42, 43], "evaluate_block_s": 5, "metric": [5, 24, 30, 31, 42, 46], "inference_batch_size_per_devic": [5, 46], "use_accelerator_for_evalu": 5, "max_new_token": [5, 27], "inferencerargu": [5, 27], "devic": [5, 13, 14, 30, 31, 46], "do_sampl": 5, "raftalignerargu": [5, 28], "raft": [5, 44], "align": [5, 21, 28, 44], "output_reward_path": [5, 28], "output_min_length": [5, 28], "output_max_length": [5, 28], "num_raft_iter": [5, 46], "raft_batch_s": [5, 46], "top_reward_percentag": [5, 46], "collection_strategi": [5, 46], "benchmarkingargu": 5, "lm_evaluation_metr": 5, "pipeline_argument_map": 5, "autoargu": [5, 45], "choos": [5, 30, 31, 39, 46, 47], "get_pipeline_args_class": [5, 45], "python": [6, 7, 39, 42, 43, 48], "code": [6, 7, 31, 39], "method": [6, 7, 13, 14, 24, 30, 31, 39, 46, 48], "manipul": [6, 7], "backend": [6, 7, 13, 14, 31], "hug": [6, 7, 41], "face": [6, 7], "dictionari": [6, 7, 24, 25, 30, 31], "retriev": [6, 7], "dataset_typ": 6, "text_onli": [6, 19, 41, 42, 46, 47], "text2text": [6, 42, 44], "float_onli": 6, "key_typ": 6, "key_inst": 6, "instanc": [6, 7, 13, 14, 19, 24, 25, 30, 31, 39, 41, 46, 47, 48], "data_arg": [6, 7, 20, 24, 25, 27, 28, 45], "kwarg": [6, 7, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23, 25, 28, 30, 31], "object": [6, 7, 19, 24, 25, 27, 28, 30, 31], "given": [6, 7, 19, 24, 25, 27, 28, 30, 31, 39, 42, 46, 47], "requir": [6, 7, 24, 25, 27, 28, 39, 46, 47, 48], "posit": [6, 7, 13, 14, 19, 25, 28, 39, 46, 47, 48], "keyword": [6, 7, 13, 14, 19, 25, 28, 31], "_check_data_format": [6, 7], "check": [6, 7, 31, 39], "structur": [6, 7, 46, 47], "match": [6, 7, 39], "rais": [6, 7, 31], "from_dict": [6, 7], "dict_obj": [6, 7], "return": [6, 7, 13, 14, 20, 24, 25, 27, 28, 30, 31, 33, 39, 46, 47], "format": [6, 7, 44], "key_1": [6, 7, 41], "value_1": [6, 7, 41], "key_2": [6, 7, 41], "2": [6, 7, 28, 39, 41, 44, 45, 48], "value_2": [6, 7, 41], "self": [6, 7, 30, 31, 34, 36, 46], "classmethod": [6, 7, 9, 20], "create_from_dict": [6, 7], "to_dict": [6, 7], "get_backend": [6, 7], "get_backend_dataset": [6, 7], "backend_dataset": [6, 7], "get_fingerprint": [6, 7], "fingerprint": [6, 7], "which": [6, 7, 13, 14, 21, 23, 24, 31, 39, 41, 46, 47, 48], "get_data_arg": [6, 7], "get_typ": [6, 7], "internal_vers": 8, "__version__": [8, 38], "get": [9, 19, 28, 31, 39, 42, 43, 44, 45, 47], "correct": [9, 46], "automodel": 9, "get_model": 9, "model_arg": [9, 13, 14, 19, 20, 24, 25, 27, 28, 45], "basemodel": [10, 11, 12, 18, 28], "abc": [10, 11, 12, 17, 18, 22], "helper": [10, 11, 12, 17, 18, 22, 31], "standard": [10, 11, 12, 17, 18, 22], "wai": [10, 11, 12, 17, 18, 22, 30, 31, 39, 41, 42, 43, 46, 47], "inherit": [10, 11, 12, 17, 18, 22, 31], "one": [11, 12, 30, 31, 39, 42, 45, 46, 47], "line": [11, 12, 39], "summari": [11, 12, 31], "program": [11, 12, 33, 46], "termin": [11, 12], "period": [11, 12, 39], "leav": [11, 12, 39, 46], "blank": [11, 12], "rest": [11, 12], "docstr": [11, 12], "should": [11, 12, 30, 31, 39, 46, 47], "overal": [11, 12, 13, 14, 48], "descript": [11, 12, 31, 44], "mai": [11, 12, 30, 31, 39, 41, 42, 46, 47], "brief": [11, 12], "export": [11, 12], "usag": [11, 12, 39], "typic": [11, 12, 39, 46, 47], "foo": [11, 12], "classfoo": [11, 12], "bar": [11, 12], "functionbar": [11, 12], "decodermodel": [11, 13], "encoderdecodermodel": [12, 14], "call": [13, 14, 30, 31, 39, 46], "hfdecodermodel": [13, 14, 24], "wrapper": [13, 14, 31], "around": [13, 14, 39], "ha": [13, 14, 24, 30, 31, 39, 41], "__init__": [13, 14], "ar": [13, 14, 30, 31, 39, 41, 42, 43, 46, 47, 48], "fine": [13, 14, 30, 31, 46, 47, 48], "take": [13, 14, 24, 28, 30, 31, 46], "tune_strategi": [13, 14], "attent": [13, 14], "mask": [13, 14], "fed": [13, 14, 31], "support": [13, 14, 42, 43, 44], "normal": [13, 14, 24, 39], "allow": [13, 14, 31, 39, 48], "howev": [13, 14, 39, 43, 46, 48], "strategi": [13, 14, 46], "yet": [13, 14], "implement": [13, 14, 31, 39, 42, 46], "conveni": [13, 14, 39, 46, 48], "variou": [13, 14, 31, 41, 48], "nlp": [13, 14, 39], "classif": [13, 14, 31], "question": [13, 14, 28, 39, 41], "answer": [13, 14, 33, 39, 41, 42, 46, 47], "logger": [13, 14, 25, 28, 31], "models_support_flash_attent": 13, "llamaforcausallm": 13, "gptneoforcausallm": 13, "gpu": [13, 14, 30, 31, 46], "use_acceler": [13, 14], "revis": [13, 14, 19], "etc": [13, 14, 19, 30, 31, 39, 46, 48], "configu": [13, 14], "add_special_token": 13, "true": [13, 24, 25, 31, 33, 46, 47], "full": [13, 14, 30, 39, 46, 47, 48], "tokenized_dataset": [13, 14, 25, 45], "without": [13, 31, 39, 46, 47], "ani": [13, 31, 39, 46, 47, 48], "lead": [13, 39, 46], "trail": 13, "special": [13, 46, 48], "thei": [13, 30, 31, 39, 41, 46, 47], "begin": [13, 46], "Of": 13, "sentenc": [13, 39], "end": [13, 31], "encod": [13, 14, 24, 41], "union": [13, 14, 30, 31], "perform": [13, 14, 24, 25, 27, 28, 31, 46, 47, 48], "process": [13, 14, 24, 25, 27, 28, 30, 31, 39, 44, 45, 46, 47, 48], "output": [13, 14, 24, 28, 31, 33, 39, 41], "hello": 13, "world": [13, 39, 46], "101": [13, 39], "7592": 13, "1010": 13, "2088": 13, "102": 13, "batch": [13, 24, 30, 31, 33, 36, 46, 47], "input_id": [13, 47], "attention_mask": [13, 34, 36, 47], "token_type_id": 13, "tensor": [13, 30, 31, 36], "decod": [13, 14, 24, 33, 41], "singl": [13, 30, 31, 39, 41, 46, 47], "prompt": [13, 14, 28, 41, 46, 47, 48], "merge_lora_weight": [13, 14], "save": [13, 14, 30, 31, 43, 48], "dir": [13, 14, 42], "save_full_model": [13, 14], "get_max_length": [13, 14, 45], "max": [13, 14, 24], "accept": [13, 14, 19, 24, 30, 31, 41, 46], "term": [13, 14, 39, 46], "get_token": [13, 14], "get_backend_model": [13, 14], "hfencoderdecodermodel": 14, "abstract": [14, 21, 23], "regress": [18, 19], "regressionmodel": [18, 19, 28], "textregressionmodel": 19, "register_inference_funct": 19, "inference_func": 19, "regist": 19, "result": [19, 39, 46, 48], "onli": [19, 31, 39, 41, 42, 45, 46, 47, 48], "its": [20, 31, 39, 46, 48], "pipeline_map": 20, "autopipelin": [20, 45], "design": [20, 48], "get_pipelin": [20, 45], "pipeline_nam": [20, 45], "pipeline_arg": [20, 45], "basetun": [21, 23, 25], "subclass": [21, 23, 30, 31], "basepipelin": [21, 22, 23, 24, 27], "basealign": [21, 28], "_check_if_align": 21, "reward_model": [21, 28], "_check_if_tun": 23, "packag": [24, 44, 48], "constructor": 24, "three": [24, 39, 41, 46, 47], "relat": [24, 46, 47, 48], "evaluator_arg": 24, "other": [24, 30, 31, 39, 46, 47, 48], "two": [24, 30, 31, 39, 42, 46, 47], "create_dataload": [24, 27], "test": [24, 31, 39, 41, 43, 46, 47, 48], "loader": 24, "iter": [24, 28, 30, 31, 46], "over": [24, 39, 41, 46, 47], "mini": 24, "Then": [24, 43, 46, 47], "write": [24, 39], "log": [24, 31, 39, 42], "consol": 24, "bias": 24, "_match": 24, "predicted_answ": 24, "groundtruth": 24, "accuraci": [24, 39, 46, 47, 48], "verbos": 24, "tunablemodel": [24, 25, 27, 45], "_evaluate_acc_with_acceler": 24, "_evaluate_acc_with_deepspe": 24, "_evaluate_ppl": 24, "_evaluate_nl": 24, "neg": [24, 39, 42, 46, 47, 48], "likelihood": [24, 39, 42], "nll": [24, 39, 44], "n": [24, 39, 42, 48], "sum_": 24, "j": [24, 46, 47], "w_i": 24, "ln": 24, "p": 24, "w_": 24, "context_window": 24, "sampl": [24, 31, 39, 41, 46, 47], "th": 24, "here": [24, 30, 31, 39, 46, 47], "start": [24, 30, 31, 46, 47], "p_": 24, "window_length": 24, "finetuner_arg": 25, "group_text": [25, 45], "model_max_length": [25, 45], "group": [25, 31, 45], "togeth": [25, 31, 46], "form": [25, 30, 31, 46], "transform_dataset_in_plac": 25, "rstrip_partial_utf8": 27, "inferencer_arg": 27, "100": [27, 31, 47], "output_dataset": 27, "stream_infer": 27, "context": [27, 31, 39, 46], "token_per_step": 27, "end_str": 27, "input_dataset": 27, "raftalign": 28, "aligner_arg": 28, "raft_aligner_arg": 28, "_initialize_train": 28, "training_arg": [28, 30, 31], "trainer": [28, 30, 31], "_load_dataset": 28, "selected_dataset": 28, "prepar": [28, 31, 42, 46, 47, 48], "everi": [28, 31], "_load_input_dataset": 28, "dataload": [28, 31, 33], "torch": [28, 30, 31, 33, 36], "_clean_text": [28, 46], "_discard_sampl": [28, 46], "_get_batch_dataset_top": 28, "batch_input": 28, "alpha": 28, "iter_id": 28, "16": 28, "48": 28, "infer_batch_s": 28, "8": [28, 39, 46, 48], "generation_kwarg": 28, "_get_batch_dataset_loc": 28, "k": [28, 39, 46, 47], "feed": [28, 31], "reward": [28, 44], "peft": 30, "pefttrain": 30, "featur": [30, 31, 39], "complet": [30, 31, 46, 48], "eval": [30, 31, 46, 47], "loop": [30, 31], "pytorch": [30, 31], "optim": [30, 31, 46], "pretrainedmodel": [30, 31], "nn": [30, 31, 47], "predict": [30, 31, 39], "model_init": [30, 31], "must": [30, 31, 45, 48], "tip": [30, 31], "work": [30, 31, 39, 46, 47], "you": [30, 31, 39, 41, 42, 43, 46, 47, 48], "still": [30, 31, 39, 46, 47, 48], "your": [30, 31, 44, 46, 47], "own": [30, 31, 39, 41, 42, 46, 47], "long": [30, 31, 39, 41, 46], "same": [30, 31, 46, 47], "tweak": [30, 31], "Will": [30, 31], "basic": [30, 31], "tmp_trainer": [30, 31], "current": [30, 31, 39, 41, 42], "data_col": [30, 31], "datacol": [30, 31], "element": [30, 31, 39, 48], "train_dataset": [30, 31, 47], "eval_dataset": [30, 31, 47], "default_data_col": [30, 31], "datacollatorwithpad": [30, 31], "otherwis": [30, 31], "iterabledataset": [30, 31], "column": [30, 31], "forward": [30, 31, 34, 36], "remov": [30, 31, 46], "note": [30, 31, 39, 42, 46, 48], "random": [30, 31, 33, 46], "fashion": [30, 31], "either": [30, 31, 46], "intern": [30, 31, 39], "attribut": 30, "ident": [30, 31], "all": [30, 31, 39, 41, 43, 46, 47, 48], "manual": [30, 31, 39], "seed": [30, 31, 33], "epoch": [30, 31, 39, 46], "have": [30, 31, 39, 41, 42, 43, 46, 47, 48], "set_epoch": [30, 31], "rng": [30, 31], "prepend": [30, 31], "kei": [30, 31, 34, 39, 41, 42, 46, 47], "pretrainedtokenizerbas": [30, 31], "preprocess": [30, 31, 47], "pad": [30, 31], "along": [30, 31], "make": [30, 31, 39, 42, 46, 47, 48], "easier": [30, 31], "rerun": [30, 31], "interrupt": [30, 31], "reus": [30, 31], "callabl": [30, 31], "instanti": [30, 31], "new": [30, 31, 39, 42, 46, 47, 48], "zero": [30, 31], "optuna": [30, 31], "rai": [30, 31], "sigopt": [30, 31], "trial": [30, 31, 39, 46, 47], "abl": [30, 31, 39, 46, 47], "architectur": [30, 31], "accord": [30, 31, 39, 46], "hyper": [30, 31, 44], "layer": [30, 31], "count": [30, 31, 39], "inner": [30, 31], "dropout": [30, 31], "probabl": [30, 31, 39, 46, 47], "compute_metr": [30, 31], "evalpredict": [30, 31], "comput": [30, 31], "callback": [30, 31], "trainercallback": [30, 31], "add": [30, 31, 42, 46], "those": [30, 31, 39, 46], "detail": [30, 31, 39, 42, 44, 46, 47], "want": [30, 31, 42, 46, 47], "remove_callback": [30, 31], "lr_schedul": [30, 31], "lambdalr": [30, 31], "schedul": [30, 31], "adamw": [30, 31], "get_linear_schedule_with_warmup": [30, 31], "preprocess_logits_for_metr": [30, 31], "logit": [30, 31], "right": [30, 31, 39, 46], "befor": [30, 31, 46, 48], "them": [30, 31, 39, 41, 42, 43, 46, 47, 48], "step": [30, 31, 42, 44, 46], "label": [30, 31, 39, 46, 47], "onc": [30, 31], "desir": [30, 31, 46, 47], "modif": [30, 31], "made": [30, 31, 39, 46, 47], "reflect": [30, 31, 39], "receiv": [30, 31], "second": [30, 31, 43], "doe": [30, 31, 39, 46, 48], "alwai": [30, 31, 39, 46, 47], "point": [30, 31, 46], "core": [30, 31], "model_wrap": [30, 31], "most": [30, 31, 39, 41, 46, 47], "extern": [30, 31, 39], "case": [30, 31, 39, 43, 46, 47], "more": [30, 31, 39, 46, 47, 48], "wrap": [30, 31], "origin": [30, 31, 39, 43, 46, 47], "again": [30, 31], "distributeddataparallel": [30, 31], "hasn": [30, 31], "t": [30, 31, 39, 46, 47], "been": [30, 31, 39, 46], "is_model_parallel": [30, 31], "switch": [30, 31, 46, 47], "parallel": [30, 31], "mean": [30, 31, 39, 46, 47], "split": [30, 31, 46, 47], "place_model_on_devic": [30, 31], "place": [30, 31, 46, 47], "overridden": [30, 31], "is_in_train": [30, 31], "while": [30, 31, 39, 48], "_save_checkpoint": [30, 31], "_": 30, "don": [30, 46, 47], "folder": 30, "need": [30, 31, 39, 42, 43, 46, 47, 48], "peftsavingcallback": 30, "trainer_callback": [30, 31], "correctli": [30, 39, 46, 47], "_save": [30, 31], "on_train_end": 30, "state": [30, 31, 39, 46], "trainerst": 30, "trainercontrol": 30, "final": [30, 39], "best": [30, 31, 39, 46, 47], "on_epoch_end": 30, "intermedi": 30, "on_sav": 30, "event": [30, 39], "_is_native_cpu_amp_avail": 31, "default_callback": 31, "default_progress_callback": 31, "is_sagemaker_mp_post_1_10": 31, "skip_first_batch": 31, "training_args_nam": 31, "bin": 31, "trainer_state_nam": 31, "trainer_st": 31, "optimizer_nam": 31, "pt": 31, "scheduler_nam": 31, "scaler_nam": 31, "scaler": 31, "rafttrain": 31, "modeling_util": 31, "tokenization_utils_bas": 31, "trainer_util": 31, "add_callback": 31, "In": [31, 39, 42, 43, 46, 47], "member": [31, 46], "pop_callback": 31, "found": [31, 39, 46, 48], "error": 31, "pop": 31, "_move_model_to_devic": 31, "_set_signature_columns_if_need": 31, "_remove_unused_column": 31, "_get_collator_with_removed_column": 31, "collat": 31, "unus": 31, "_get_train_sampl": 31, "sampler": 31, "get_train_dataload": 31, "__len__": 31, "inject": 31, "behavior": 31, "_get_eval_sampl": 31, "get_eval_dataload": 31, "get_test_dataload": 31, "test_dataset": 31, "create_optimizer_and_schedul": 31, "num_training_step": 31, "setup": [31, 44, 46], "learn": [31, 46, 47, 48], "rate": [31, 46], "we": [31, 39, 41, 42, 44, 45, 46, 47, 48], "reason": [31, 46, 47], "well": [31, 39, 46, 48], "someth": [31, 39, 46, 47], "els": [31, 45, 46, 47], "init": 31, "through": [31, 39], "create_optim": 31, "create_schedul": 31, "static": 31, "get_optimizer_cls_and_kwarg": 31, "session": 31, "up": [31, 39, 46, 47], "do": [31, 39, 46, 47, 48], "num_exampl": 31, "access": [31, 39, 43, 48], "exist": 31, "estim": 31, "_hp_search_setup": 31, "hp": 31, "search": [31, 46, 48], "_report_to_hp_search": 31, "_tune_save_checkpoint": 31, "call_model_init": 31, "torch_jit_model_ev": 31, "ipex_optimize_model": 31, "float32": 31, "_wrap_model": 31, "resume_from_checkpoint": 31, "ignore_keys_for_ev": 31, "is_first_tim": 31, "main": [31, 42, 45, 46, 48], "entri": 31, "local": [31, 39, 46], "previou": [31, 46, 47], "equal": [31, 39], "last": [31, 46, 47], "present": [31, 46], "resum": 31, "hyperparamet": 31, "ignor": 31, "gather": [31, 46], "dure": [31, 39], "hide": [31, 46, 47], "deprec": 31, "_one_train": 31, "batch_siz": [31, 33, 46], "_inner_training_loop": 31, "serv": [31, 39, 46, 48], "time": [31, 36, 39, 46, 47], "updat": [31, 46, 47], "_get_output_dir": 31, "_load_from_checkpoint": 31, "_load_best_model": 31, "_issue_warnings_after_load": 31, "load_result": 31, "_maybe_log_save_evalu": 31, "tr_loss": 31, "_load_rng_stat": 31, "_load_optimizer_and_schedul": 31, "hyperparameter_search": 31, "hp_space": 31, "compute_object": 31, "n_trial": 31, "20": [31, 39, 46], "direct": [31, 48], "minim": 31, "hpsearchbackend": 31, "hp_name": 31, "bestrun": 31, "launch": 31, "quantiti": 31, "determin": [31, 39], "loss": [31, 47], "sum": 31, "warn": 31, "To": [31, 41, 46, 47, 48], "reiniti": 31, "incompat": 31, "so": [31, 39, 46, 47, 48], "space": [31, 46, 47], "default_hp_space_optuna": 31, "default_hp_space_rai": 31, "default_hp_space_sigopt": 31, "depend": [31, 39, 46, 47], "maxim": [31, 48], "default_compute_object": 31, "greater": [31, 39], "lower": [31, 39], "pick": 31, "valid": 31, "training_util": 31, "instal": [31, 42], "create_studi": 31, "see": [31, 39, 46, 47], "http": [31, 39, 42, 46, 47, 48], "readthedoc": 31, "io": [31, 39, 46, 48], "en": [31, 39], "stabl": 31, "refer": [31, 42, 44, 46, 48], "studi": [31, 46, 47], "html": [31, 39, 46], "doc": 31, "latest": 31, "api_doc": 31, "execut": [31, 42], "app": 31, "com": [31, 39, 42, 46, 48], "endpoint": 31, "experi": [31, 39, 46], "run_summari": 31, "watch": 31, "_prepare_input": 31, "nest": 31, "convert": [31, 33, 43], "handl": [31, 46], "potenti": [31, 39], "compute_loss_context_manag": 31, "manag": 31, "autocast_smart_context_manag": 31, "cache_en": 31, "appropri": [31, 39, 46, 47], "autocast": 31, "situat": [31, 39, 46, 47], "training_step": 31, "target": [31, 48], "unpack": 31, "being": [31, 39, 46, 47], "expect": [31, 39], "compute_loss": 31, "return_output": 31, "how": [31, 39, 44, 46, 47], "By": [31, 43, 46, 48], "is_local_process_zero": 31, "machin": [31, 48], "is_world_process_zero": 31, "global": [31, 46], "go": [31, 39, 43, 46], "save_model": 31, "_internal_cal": 31, "reload": 31, "from_pretrain": 31, "_save_tpu": 31, "state_dict": 31, "store_flo": 31, "_sorted_checkpoint": 31, "checkpoint_prefix": 31, "prefix_checkpoint_dir": 31, "use_mtim": 31, "_rotate_checkpoint": 31, "ignore_kei": 31, "metric_key_prefix": 31, "respons": [31, 33, 39, 46, 47, 48], "wish": 31, "lst": 31, "prefix": [31, 47], "bleu": 31, "eval_bleu": 31, "come": [31, 39], "predictionoutput": 31, "like": [31, 39, 42, 46, 47, 48], "test_bleu": 31, "becaus": [31, 39, 46], "re": [31, 46, 47], "dynam": 31, "concaten": [31, 39], "arrai": [31, 39], "index": [31, 48], "namedtupl": 31, "follow": [31, 41, 42, 46, 47, 48], "np": 31, "ndarrai": 31, "label_id": 31, "evaluation_loop": 31, "prediction_loss_onli": 31, "evalloopoutput": 31, "share": [31, 46], "both": [31, 39, 46, 48], "_nested_gath": 31, "numpi": [31, 33], "_pad_across_process": 31, "pad_index": 31, "recurs": [31, 39], "safe": [31, 39, 46, 47], "prediction_step": 31, "floating_point_op": 31, "oper": 31, "backward": 31, "anoth": [31, 39, 46], "init_git_repo": 31, "at_init": 31, "git": [31, 42, 48], "repo": [31, 42, 46], "hub_model_id": 31, "overwrite_output_dir": 31, "might": [31, 46, 47], "wipe": 31, "out": [31, 39, 46, 47, 48], "create_model_card": 31, "licens": [31, 39, 46], "model_nam": [31, 42], "finetuned_from": 31, "dataset_tag": 31, "dataset_arg": 31, "draft": 31, "card": 31, "avail": [31, 39, 41, 42, 48], "applic": [31, 39, 48], "hub": [31, 39], "One": [31, 39], "identifi": 31, "_push_from_checkpoint": 31, "checkpoint_fold": 31, "push_to_hub": 31, "commit_messag": 31, "upload": 31, "push": 31, "finish": [31, 42], "url": [31, 48], "repositori": [31, 39, 48], "track": [31, 46], "progress": 31, "prediction_loop": 31, "_gather_and_numpifi": 31, "_add_sm_patterns_to_gitignor": 31, "sagemak": 31, "pattern": 31, "gitignor": 31, "commonli": [32, 39, 48], "text_only_dataset_descript": 32, "text_only_dataset_detail": 32, "text2text_dataset_descript": 32, "text2text_dataset_detail": 32, "float_only_dataset_descript": 32, "text_only_dataset_long_descrit": 32, "text2text_dataset_long_descrit": 32, "dataset_description_map": 32, "instance_fields_map": 32, "set_random_se": 33, "cuda": 33, "load_data": 33, "file_nam": 33, "len": [33, 39, 45, 47], "batchliz": 33, "shuffl": 33, "answer_extract": 33, "funtion": 33, "plain": 33, "b": [33, 42], "c": [33, 39], "d": [33, 39, 46, 47], "mutipl": 33, "qa": [33, 39], "_attn": 34, "queri": 34, "head_mask": 34, "hidden_st": [34, 36], "layer_past": 34, "use_cach": [34, 36], "output_attent": [34, 36], "replace_gpt_neo_attn_with_flash_attn": 34, "position_id": 36, "past_key_valu": 36, "shape": 36, "x": [36, 39, 46, 47], "channel": 36, "bsz": 36, "q_len": 36, "_prepare_decoder_attention_mask": 36, "input_shap": 36, "inputs_emb": 36, "past_key_values_length": 36, "replace_llama_attn_with_flash_attn": 36, "9": [39, 42, 48], "style": 39, "larg": [39, 46, 48], "huge": 39, "challeng": [39, 46, 47], "sinc": [39, 41, 46], "breakthrough": 39, "chatgpt": [39, 48], "On": 39, "hand": [39, 46, 48], "research": [39, 46], "engin": [39, 41], "reliabl": [39, 46, 48], "compar": [39, 46, 47, 48], "decid": [39, 42], "certain": [39, 46, 47], "scenario": 39, "monitor": 39, "avoid": [39, 46], "issu": [39, 43, 46, 48], "forget": 39, "recent": 39, "vicuna": 39, "introduc": [39, 46, 48], "comparison": [39, 46], "human": [39, 42, 46, 47, 48], "chatbot": 39, "arena": 39, "pioneer": 39, "invok": 39, "gpt": [39, 46, 47, 48], "4": [39, 41, 46, 48], "expens": 39, "neither": 39, "scalabl": [39, 48], "nor": 39, "articl": 39, "cheap": 39, "easi": [39, 46, 47], "aspect": 39, "everyon": 39, "commun": [39, 46, 48], "toolkit": [39, 46, 48], "our": [39, 41, 42, 43, 44, 45, 46, 48], "correspond": [39, 41], "corpu": 39, "itself": 39, "abil": [39, 48], "multi": 39, "round": [39, 46], "convers": [39, 46], "math": 39, "problem": [39, 44, 46, 47], "solv": 39, "role": [39, 46], "plai": 39, "corpora": 39, "quantit": 39, "idea": [39, 46, 47], "behind": 39, "correl": 39, "essai": 39, "understand": [39, 46, 48], "just": [39, 46, 47], "chess": 39, "master": 39, "memor": 39, "endgam": 39, "chessboard": 39, "besid": 39, "similar": [39, 43, 46], "ppl": 39, "nevertheless": 39, "intrins": 39, "induc": 39, "unfair": 39, "between": 39, "smaller": [39, 46], "vocabulari": 39, "inher": 39, "longer": 39, "level": [39, 48], "thu": 39, "instead": 39, "advantag": 39, "involv": [39, 46, 47], "As": [39, 41, 46, 47], "good": [39, 43, 46, 47], "experiment": 39, "find": [39, 46, 47], "tabl": [39, 42, 46], "tradit": [39, 46], "winogrand": 39, "boolq": 39, "arc_": 39, "hellaswag": 39, "piqa": 39, "obqa": 39, "arc_c": 39, "averag": [39, 48], "bloom": [39, 48], "3b": [39, 46, 47], "58": [39, 46, 47, 48], "7": [39, 46, 48], "61": [39, 48], "6": [39, 46, 48], "59": [39, 48], "5": [39, 46, 47, 48], "52": [39, 46, 47], "70": [39, 48], "42": 39, "30": [39, 46, 48], "53": 39, "1b": 39, "64": [39, 46, 47, 48], "62": 39, "65": [39, 46, 47, 48], "73": [39, 48], "35": [39, 48], "33": 39, "56": [39, 48], "3": [39, 41, 42, 44, 48], "opt": [39, 48], "9b": 39, "66": [39, 48], "67": [39, 48], "76": 39, "37": [39, 48], "34": 39, "13b": 39, "69": [39, 46, 47, 48], "39": [39, 46, 48], "llama": [39, 44, 46, 47, 48], "7b": [39, 43, 46, 47, 48], "78": [39, 48], "41": 39, "68": [39, 48], "74": [39, 48], "79": [39, 46, 47], "44": [39, 48], "86": 39, "228": 39, "245": 39, "134": 39, "135": 39, "85": [39, 48], "215": 39, "81": 39, "237": 39, "130": 39, "96": 39, "129": 39, "200": 39, "224": 39, "125": [39, 46], "124": 39, "82": 39, "198": 39, "220": 39, "97": 39, "123": 39, "167": 39, "71": [39, 46, 47], "214": 39, "121": 39, "113": 39, "153": 39, "207": 39, "119": 39, "57": [39, 48], "83": 39, "109": 39, "figur": [39, 46], "abov": [39, 41, 47], "roughli": 39, "magnitud": 39, "gap": 39, "entail": 39, "section": [39, 46], "comprehens": 39, "summar": 39, "due": [39, 43], "limit": 39, "demonstr": [39, 46, 48], "partial": 39, "sheet": 39, "0501": 39, "optimalscal": [39, 46, 48], "github": [39, 42, 46, 48], "task_guid": 39, "robin": 39, "popular": [39, 46, 47], "try": [39, 46, 47], "onlin": 39, "demo": 39, "especi": 39, "observ": [39, 46, 48], "foundat": [39, 46, 48], "obtain": [39, 43, 46, 48], "gain": [39, 46, 48], "achiev": [39, 46, 48], "better": [39, 46, 48], "en_multi_round_chat": 39, "en_singe_round_chat": 39, "188": 39, "213": 39, "164": 39, "181": 39, "172": 39, "163": 39, "184": 39, "173": 39, "155": 39, "175": 39, "165": 39, "150": 39, "170": 39, "160": 39, "146": 39, "qualit": 39, "turn": [39, 46, 47], "effortlessli": 39, "slight": 39, "mistak": [39, 46], "sometim": [39, 46], "doesn": [39, 46], "item": [39, 42], "mexican": 39, "food": [39, 46], "cuisin": 39, "recommend": [39, 46, 47], "omit": 39, "r1": 39, "capit": 39, "usa": 39, "unit": [39, 46], "washington": 39, "district": 39, "columbia": 39, "locat": 39, "east": 39, "coast": [39, 46], "countri": 39, "northern": 39, "part": 39, "maryland": 39, "georg": 39, "presid": 39, "feder": 39, "directli": [39, 42, 43, 48], "administ": 39, "govern": 39, "citi": 39, "home": [39, 46, 47], "mani": [39, 46, 47], "nation": [39, 46], "landmark": 39, "white": 39, "hous": [39, 46, 47], "capitol": 39, "build": [39, 46, 47], "suprem": 39, "court": 39, "museum": 39, "monument": 39, "cultur": [39, 46, 47], "institut": 39, "virginia": 39, "r2": 39, "scene": 39, "restaur": 39, "american": 39, "classic": 39, "There": [39, 46, 47], "dish": [39, 46], "hamburg": 39, "hot": [39, 46], "dog": 39, "appl": 39, "pie": 39, "seafood": 39, "chesapeak": 39, "bai": 39, "known": 39, "fresh": 39, "crab": 39, "cake": 39, "shrimp": 39, "oyster": 39, "ethnic": 39, "popul": 39, "chines": 39, "japanes": 39, "korean": 39, "barbecu": 39, "pull": 39, "pork": 39, "rib": 39, "brisket": 39, "donut": 39, "famou": 39, "happi": [39, 46, 47], "shop": 39, "varieti": 39, "flavor": 39, "top": [39, 46], "street": 39, "truck": 39, "stand": 39, "falafel": 39, "kebab": 39, "taco": 39, "These": 39, "few": [39, 46, 48], "wide": [39, 48], "rang": [39, 47, 48], "visit": 39, "soul": 39, "southern": 39, "bold": 39, "hearti": 39, "portion": 39, "fri": [39, 46], "chicken": 39, "collard": 39, "green": 39, "macaroni": 39, "chees": 39, "ethiopian": 39, "spici": [39, 46], "injera": 39, "sourdough": 39, "flatbread": 39, "wat": 39, "veget": [39, 46], "stew": 39, "kitfo": 39, "meat": [39, 46], "pasta": 39, "bbq": 39, "thrive": 39, "slow": 39, "cook": [39, 46], "side": [39, 46], "spot": 39, "ben": 39, "chili": 39, "bowl": 39, "pete": 39, "vegetarian": 39, "smoke": 39, "barrel": 39, "diplomaci": 39, "culinari": 39, "indian": 39, "r3": 39, "fifth": 39, "sure": [39, 46, 47], "mention": 39, "usual": 39, "flame": 39, "heat": [39, 46, 47], "coal": 39, "often": [39, 46], "marin": 39, "sauc": [39, 46], "coleslaw": 39, "bake": [39, 46], "bean": 39, "corn": 39, "cob": 39, "pit": 39, "smokehous": 39, "joint": 39, "salt": [39, 46], "sovereign": 39, "offer": [39, 46], "delici": 39, "margarita": 39, "adam": 39, "morgan": 39, "authent": 39, "year": [39, 46, 48], "al": 39, "pastor": 39, "grill": 39, "enchilada": 39, "fill": 39, "tortilla": 39, "chile": 39, "relleno": 39, "stuf": 39, "pepper": 39, "el": 39, "comal": 39, "cozi": 39, "littl": 39, "height": 39, "neighborhood": 39, "mole": 39, "rich": 39, "blend": 39, "spice": 39, "chocol": [39, 46], "de": 39, "carnita": 39, "crispi": 39, "queso": 39, "casa": 39, "oaxaca": 39, "upscal": 39, "shaw": 39, "menu": [39, 46], "modern": 39, "cevich": 39, "raw": [39, 41], "fish": 39, "lime": 39, "juic": 39, "negro": 39, "dark": 39, "nogada": 39, "poblano": 39, "walnut": 39, "honei": 39, "king": 39, "chain": 39, "area": [39, 48], "burrito": 39, "afford": [39, 46, 47], "price": 39, "carn": 39, "asada": 39, "quesadilla": 39, "lo": 39, "No": 39, "small": 39, "casual": 39, "adobada": 39, "real": 39, "histori": [39, 46, 47], "collect": [39, 46], "183": 39, "english": 39, "total": 39, "447": 39, "break": 39, "multipl": [39, 46, 48], "pair": [39, 41, 42], "q1": 39, "a1": 39, "q2": 39, "a2": 39, "q3": 39, "a3": 39, "q": 39, "ouptut": 39, "common": [39, 41, 48], "sens": 39, "acquir": [39, 48], "factual": 39, "knowledg": [39, 48], "properli": [39, 46], "regard": 39, "degrad": 39, "competit": 39, "arc_easi": 39, "60": [39, 48], "72": [39, 48], "38": 39, "55": [39, 48], "63": [39, 48], "77": 39, "40": [39, 48], "75": [39, 48], "254": 39, "89": 39, "266": 39, "147": 39, "106": 39, "219": 39, "258": 39, "151": 39, "105": 39, "141": 39, "95": 39, "88": 39, "262": 39, "149": 39, "140": 39, "240": 39, "139": 39, "surpris": 39, "actual": [39, 46, 47], "consequ": 39, "hallucin": 39, "tend": [39, 46], "give": [39, 46, 47], "plausibl": 39, "incorrect": 39, "irrelev": 39, "explan": 39, "phenomenon": [39, 46, 47], "attempt": 39, "fit": 39, "suffer": 39, "less": 39, "conjectur": 39, "improv": [39, 46, 47, 48], "brought": 39, "higher": [39, 46], "qualiti": [39, 46], "sharegpt": 39, "900mb": 39, "wa": [39, 46], "600mb": 39, "suggest": [39, 46], "stage": 39, "critic": 39, "monei": 39, "compet": [39, 48], "show": [39, 44, 46, 47], "possess": 39, "friend": 39, "door": 39, "lock": 39, "smell": 39, "ga": 39, "window": [39, 46], "quickli": 39, "possibl": 39, "fire": [39, 46, 47], "depart": [39, 46], "compani": 39, "flammabl": 39, "danger": 39, "even": 39, "deadli": 39, "ventil": 39, "could": [39, 46, 47], "caus": [39, 46, 47], "explos": 39, "escap": 39, "cannot": 39, "stai": [39, 46], "calm": 39, "wait": 39, "arriv": 39, "injuri": 39, "damag": [39, 46, 47, 48], "yourself": 39, "addition": [39, 46, 47], "illeg": 39, "enter": 39, "properti": 39, "permiss": 39, "homeown": 39, "locksmith": 39, "assist": [39, 42, 46, 47], "unabl": 39, "emerg": 39, "servic": 39, "polic": 39, "meantim": 39, "lighter": 39, "leak": 39, "evacu": 39, "immedi": 39, "inde": 39, "injur": [39, 46], "bring": [39, 46], "my": [39, 46, 47], "pet": 39, "ferret": 39, "beauti": 39, "pacif": 39, "island": 39, "attend": 39, "icml": 39, "m": [39, 46, 47], "sorri": 39, "am": [39, 46], "awar": [39, 48], "polici": [39, 46], "confer": 39, "would": [39, 46, 47], "organ": [39, 46, 47], "author": [39, 48], "procedur": [39, 46, 47], "permit": 39, "proper": 39, "carri": [39, 46, 47], "diseas": 39, "peopl": [39, 46, 47], "toxoplasmosi": 39, "salmonellosi": 39, "priorit": 39, "health": 39, "safeti": [39, 46], "crowd": 39, "held": [39, 48], "hawaii": 39, "strictli": 39, "prohibit": 39, "carrier": 39, "rabi": 39, "viru": 39, "eleuth": [39, 42], "ai": [39, 46, 47, 48], "lm": [39, 44], "har": [39, 42], "eleutherai": [39, 42, 46, 47], "loyal": 39, "obei": 39, "ethic": 39, "legal": [39, 48], "gpt4_en_instruct": 39, "alpaca": [39, 41, 43], "222": 39, "211": 39, "206": 39, "180": 39, "quicksort": 39, "ye": [39, 46, 47], "algorithm": [39, 44], "def": [39, 45, 46, 47], "arr": 39, "pivot": 39, "left": 39, "middl": 39, "partit": 39, "sub": 39, "than": [39, 46, 47], "appli": [39, 41, 46, 48], "sort": [39, 46, 47], "unsort": 39, "complex": 39, "o": [39, 45], "although": [39, 46, 47], "faster": 39, "practic": 39, "carefulli": 39, "chosen": [39, 42, 46, 47], "subarrai": 39, "produc": 39, "synonym": 39, "word": [39, 46], "down": 39, "advers": 39, "difficulti": 39, "hardship": 39, "troubl": [39, 46, 47], "misfortun": 39, "hard": [39, 46, 47], "unpleas": 39, "circumst": [39, 46, 47], "connot": 39, "difficult": 39, "hostil": 39, "factor": [39, 46], "enemi": 39, "natur": [39, 48], "disast": [39, 46], "mild": 39, "inconveni": 39, "major": 39, "setback": 39, "distress": 39, "financi": 39, "bad": 39, "luck": 39, "ill": 39, "fate": 39, "econom": 39, "social": 39, "struggl": 39, "oppress": 39, "afflict": 39, "calam": 39, "tribul": 39, "10": [39, 46, 47], "condit": [39, 46], "describ": 39, "impli": 39, "intens": [39, 46], "battl": 39, "conflict": 39, "obstacl": 39, "injustic": 39, "proceed": 39, "persecut": [39, 46, 47], "order": 39, "project": [39, 46], "000": 39, "filter": [39, 47], "767": 39, "effect": [39, 46, 48], "remain": 39, "too": 39, "nonsens": 39, "incomplet": 39, "domain": [39, 48], "chemistri": 39, "biologi": [39, 48], "fail": 39, "par": 39, "surpass": [39, 48], "now": [39, 43, 46], "Its": [39, 41, 48], "essenti": 39, "lmsy": 39, "org": [39, 46, 47], "benchmark": [40, 44], "open": [40, 42, 48], "llm": [40, 46], "cd": [41, 42, 43, 46], "sh": [41, 42, 43, 46, 47], "replac": [41, 46, 47], "strongli": 41, "encourag": [41, 46], "techniqu": [41, 48], "below": [41, 42, 48], "specifi": [41, 42, 46], "path_to_dataset": 41, "data_1": 41, "data_2": 41, "another_data": 41, "shall": [41, 48], "four": 41, "key_3": 41, "key_4": 41, "value_3": 41, "interpret": 41, "sample_text_1": 41, "sample_text_2": 41, "sample_text_3": 41, "example_dataset": 41, "train_50": 41, "mostli": 41, "sample_input_1": 41, "sample_output_1": 41, "sample_input_2": 41, "sample_output_2": 41, "sample_input_3": 41, "sample_output_3": 41, "test_13": 41, "easili": [42, 48], "fork": 42, "clone": [42, 48], "usernam": 42, "checkout": [42, 46], "conda": [42, 48], "y": [42, 48], "activ": [42, 46, 48], "mpi4pi": [42, 48], "pip": [42, 48], "notic": 42, "put": 42, "mkdir": 42, "mv": 42, "py": [42, 43, 46, 47], "info": 42, "local_datset_group_map": 42, "local_datset_map": 42, "local_datset_answertype_map": 42, "combin": 42, "task_combin": 42, "task_1": 42, "task_2": 42, "rememb": [42, 46], "separ": 42, "chang": [42, 46], "tee": 42, "log_dir": 42, "err": 42, "integr": 42, "benchamrk": 42, "command": [42, 46, 47, 48], "simpli": [42, 46], "lm_eval_dataset_map": 42, "pleas": [42, 46, 48], "exact": [42, 46], "similarli": 42, "slightli": 43, "copyright": 43, "facebookresearch": 43, "offici": 43, "hf": 43, "convert_llama_weights_to_hf": 43, "input_dir": 43, "model_s": 43, "enjoi": [43, 46, 47], "With": 43, "output_model": [43, 46], "run_evaluation_with_lora": 43, "cuda_visible_devic": 43, "diff": 43, "textonli": 44, "sft": 44, "introduct": 44, "supervis": 44, "merg": 44, "overview": 44, "guid": [44, 46, 47], "registr": 44, "sy": 45, "hfargumentpars": 45, "tunable_model": 45, "pars": 45, "pipelineargu": 45, "parser": 45, "argv": 45, "endswith": 45, "let": [45, 46, 47], "parse_json_fil": 45, "json_fil": 45, "abspath": 45, "parse_args_into_dataclass": 45, "todo": 45, "done": 45, "main_process_first": 45, "desc": 45, "lm_dataset": 45, "tuned_model": 45, "remark": [46, 47, 48], "built": 46, "whose": 46, "non": 46, "commerci": [46, 48], "reinforc": [46, 47], "feedback": [46, 47], "rlhf": [46, 47], "adjust": [46, 47], "instructgpt": [46, 47, 48], "paper": [46, 47], "arxiv": [46, 47], "ab": [46, 47], "2203": [46, 47], "02155": [46, 47], "rank": [46, 47], "neo": [46, 47], "skip": 46, "dahoa": [46, 47], "hh": [46, 47], "consist": [46, 47], "particular": [46, 47, 48], "prefer": [46, 47], "reject": [46, 47], "112k": [46, 47], "12": [46, 47], "5k": [46, 47], "what": [46, 47], "kind": [46, 47], "nois": [46, 47], "did": [46, 47], "dinosaur": [46, 47], "didn": [46, 47], "live": [46, 47], "realli": [46, 47], "sai": [46, 47], "guess": [46, 47], "lot": [46, 47], "read": [46, 47], "amount": [46, 47], "imagin": [46, 47], "cant": [46, 47], "stuff": [46, 47], "know": [46, 47], "facilit": 46, "reformul": 46, "ad": [46, 47], "charact": 46, "repli": 46, "hh_rlhf": [46, 47], "xiongwei": 46, "hh_rlhf_sft": 46, "bui": [46, 47], "protect": [46, 47], "cell": [46, 47], "phone": [46, 47], "pocket": [46, 47], "purs": [46, 47], "But": [46, 47], "quick": [46, 47], "interact": [46, 47], "harm": [46, 47], "parent": [46, 47], "screen": [46, 47], "thing": [46, 47], "off": [46, 47], "won": [46, 47], "anyth": [46, 47], "aren": [46, 47], "thank": [46, 47], "me": [46, 47], "welcom": [46, 47], "salam": [46, 47], "witch": [46, 47], "look": [46, 47], "book": [46, 47], "witchcraft": [46, 47], "histor": [46, 47], "salem": [46, 47], "1692": [46, 47], "interest": [46, 47], "coloni": [46, 47], "america": [46, 47], "excel": [46, 47], "religion": [46, 47], "declin": [46, 47], "magic": [46, 47], "belief": [46, 47], "sixteenth": [46, 47], "seventeenth": [46, 47], "centuri": [46, 47], "england": [46, 47], "keith": [46, 47], "thoma": [46, 47], "otherworld": [46, 47], "anthropologi": [46, 47], "superstit": [46, 47], "jack": [46, 47], "goodi": [46, 47], "popish": [46, 47], "plot": [46, 47], "prelat": [46, 47], "everett": [46, 47], "edit": [46, 47], "run_finetun": [46, 47], "modifi": [46, 47], "project_dir": [46, 47], "num_train_epoch": 46, "learning_r": 46, "2e": 46, "per_device_train_batch_s": 46, "run_finetune_with_lora": [46, 47], "fortun": [46, 47], "former": [46, 47], "rm": [46, 47], "hh_rlhf_rm_train": 46, "heater": [46, 47], "hazard": [46, 47], "tell": [46, 47], "fireplac": [46, 47], "room": [46, 47], "materi": [46, 47], "feel": [46, 47], "touch": [46, 47], "fuel": [46, 47], "surround": [46, 47], "That": [46, 47], "glad": [46, 47], "teach": [46, 47, 48], "kid": [46, 47], "fort": [46, 47], "Or": [46, 47], "elabor": [46, 47], "exactli": [46, 47], "mayb": [46, 47], "simplest": [46, 47], "pile": [46, 47], "furnitur": [46, 47], "bit": [46, 47], "taller": [46, 47], "sturdier": [46, 47], "fun": [46, 47], "explor": [46, 47], "run_reward_model": [46, 47], "superior": 46, "root": 46, "usr_nam": 46, "hh_rlhf_rm_sft_gptneo_2_7b": 46, "1659": 46, "3e": 46, "eval_step": 46, "400": 46, "load_dataset": [46, 47], "24": [46, 47, 48], "10000": [46, 47], "merge_lora": 46, "readi": 46, "clearli": 46, "heavili": 46, "influenc": 46, "data_collect": 46, "next": 46, "subsect": 46, "gpt2": 46, "1024": 46, "per": 46, "overwritten": 46, "reader": 46, "rl": 46, "environ": 46, "far": 46, "perfect": 46, "drl": 46, "ppo": 46, "exploit": 46, "theses": 46, "imperfect": 46, "attack": 46, "record": [46, 47], "heavi": 46, "burden": 46, "therefor": [46, 48], "256": 46, "discard": 46, "reduc": 46, "resourc": 46, "82147": 46, "2k": 46, "adopt": 46, "post": [46, 47], "stext": 46, "strip": 46, "reward_model_or_path": 46, "weqweasda": 46, "hh_rlhf_rm": 46, "get_reward_funct": 46, "run_raft_align": 46, "hh_rlhf_llama": 46, "rlhf_prompt": 46, "hh_rlhf_raft_align": 46, "smoothli": 46, "increas": 46, "signific": [46, 48], "drop": 46, "distinct": 46, "22": 46, "examin": 46, "occasion": 46, "detect": 46, "high": 46, "wors": 46, "eventu": 46, "half": 46, "noisi": 46, "notat": 46, "retrain": 46, "allevi": 46, "goal": [46, 48], "disabl": 46, "curv": 46, "journei": 46, "randomli": 46, "seem": 46, "redund": 46, "suspect": 46, "advanc": 46, "src": 46, "futur": 46, "contribut": 46, "girlfriend": 46, "tri": 46, "remind": 46, "her": 46, "nice": 46, "tast": 46, "compliment": 46, "kitchen": 46, "she": 46, "appreci": 46, "recip": 46, "great": 46, "spend": 46, "child": 46, "homework": 46, "ask": 46, "why": 46, "motiv": 46, "ll": 46, "extra": 46, "privileg": 46, "video": 46, "game": 46, "altern": 46, "incentiv": 46, "plan": 46, "grade": 46, "clear": 46, "incent": 46, "meaning": 46, "said": 46, "veri": 46, "think": 46, "exchang": 46, "power": [46, 48], "weather": 46, "strongest": 46, "hurrican": 46, "ever": 46, "hit": 46, "u": 46, "katrina": 46, "2005": 46, "1938": 46, "bigger": 46, "stronger": 46, "date": 46, "strong": 46, "storm": 46, "1935": 46, "florida": 46, "ve": 46, "review": 46, "had": 46, "were": 46, "categori": 46, "800": 46, "death": 46, "caribbean": 46, "led": 46, "creation": 46, "divis": 46, "ocean": 46, "atmospher": 46, "administr": 46, "firefight": 46, "occup": 46, "definit": 46, "criteria": 46, "judg": 46, "hero": 46, "who": 46, "fight": 46, "rescu": 46, "accid": 46, "sick": 46, "educ": 46, "restor": 46, "societi": 46, "copi": 46, "cat": 46, "girl": 46, "scout": 46, "samoa": 46, "cooki": 46, "okai": 46, "visual": 46, "cup": 46, "flour": 46, "teaspoon": 46, "soda": 46, "powder": 46, "sugar": 46, "melt": 46, "butter": 46, "egg": 46, "milk": 46, "chip": 46, "miniatur": 46, "chop": 46, "peanut": 46, "pecan": 46, "heard": 46, "videogam": 46, "metal": 46, "gear": 46, "solid": 46, "phantom": 46, "pain": 46, "releas": 46, "unfinish": 46, "seri": 46, "creator": 46, "hideo": 46, "kojima": 46, "konami": 46, "unusu": 46, "director": 46, "vigil": 46, "overse": 46, "opportun": 46, "he": 46, "head": 46, "hi": 46, "studio": 46, "product": [46, 48], "strand": 46, "2020": 46, "brand": 46, "knive": 46, "victorinox": 46, "w\u00fcsthof": 46, "host": 46, "guest": 46, "drink": 46, "keep": 46, "rwandan": 46, "mizuzu": 46, "deep": 46, "plantain": 46, "oil": 46, "skillet": 46, "until": 46, "golden": 46, "brown": 46, "jfk": 46, "greatest": 46, "accomplish": 46, "civil": 46, "peac": 46, "corp": 46, "propon": 46, "scienc": 46, "technologi": 46, "reform": 46, "impact": 46, "kennedi": 46, "leader": 46, "inspir": 46, "vision": 46, "care": 46, "poor": 46, "mainstream": 46, "foreign": 46, "univers": 46, "supervisor": 46, "incorrectli": 46, "explain": 46, "someon": 46, "respect": 46, "diplomat": 46, "willing": 46, "him": 46, "dedic": 46, "employe": 46, "succe": 46, "capabl": 46, "leadership": 46, "talk": 46, "dai": 46, "hate": 46, "hm": 46, "frustrat": 46, "person": 46, "patient": 46, "isn": 46, "malfunct": 46, "softwar": 46, "bug": 46, "hardwar": 46, "network": 46, "outag": 46, "thankfulli": 46, "resolv": 46, "restart": 46, "10k": 47, "12k": 47, "illustr": 47, "select": 47, "percentag": 47, "build_dataset": 47, "assum": [47, 48], "answer_posit": 47, "answer_neg": 47, "tokenized_po": 47, "tokenized_neg": 47, "chosen_input_id": 47, "chosen_attention_mask": 47, "rejected_input_id": 47, "rejected_attention_mask": 47, "data_fil": 47, "lambda": 47, "512": 47, "idx_gap": 47, "logsigmoid": 47, "chosen_reward": 47, "rejected_reward": 47, "wandb": 47, "weixiong5237": 47, "t3uwm8yp": 47, "p2ju3r1a": 47, "8fc1rcf8": 47, "7oemwynu": 47, "toolbox": 48, "friendli": 48, "speedi": 48, "entir": 48, "backbon": 48, "galactica": 48, "light": 48, "extrem": 48, "33b": 48, "25mb": 48, "storag": 48, "orient": 48, "whole": 48, "expans": 48, "except": 48, "capac": 48, "attain": 48, "intellig": 48, "convent": 48, "despit": 48, "grow": 48, "cater": 48, "maintain": 48, "lightweight": 48, "thoughtfulli": 48, "tool": 48, "publicli": 48, "thoroughli": 48, "enhanc": 48, "profici": 48, "medicin": 48, "mathemat": 48, "subject": 48, "matter": 48, "medic": 48, "emphas": 48, "pubmedqa": 48, "medmcqa": 48, "medqa": 48, "usml": 48, "50": 48, "expert": 48, "87": 48, "90": 48, "175b": 48, "46": 48, "54": 48, "27": 48, "18": 48, "43": 48, "25": 48, "49": 48, "51": 48, "moreov": 48, "mmlu": 48, "verifi": 48, "robust": 48, "anatomi": 48, "clinic": 48, "colleg": 48, "genet": 48, "profession": 48, "32": 48, "36": 48, "30b": 48, "26": 48, "23": 48, "120b": 48, "21": 48, "176b": 48, "29": 48, "gopher": 48, "280b": 48, "gpt3": 48, "constraint": 48, "unseen": 48, "incorpor": 48, "cue": 48, "relev": 48, "approach": 48, "unlock": 48, "jsonl": 48, "readm": 48, "blog": 48, "misc": 48, "kashun": 48, "titl": 48, "publish": 48, "journal": 48, "howpublish": 48, "aim": 48, "streamlin": 48, "intend": 48, "li": 48, "sole": 48, "guarante": 48, "compon": 48, "risk": 48, "liabil": 48, "associ": 48, "technic": 48, "advic": 48, "indirect": 48, "incident": 48, "consequenti": 48, "improp": 48, "crucial": 48, "highlight": 48, "probabilist": 48, "seek": 48, "reli": 48, "outcom": 48, "account": 48, "relianc": 48, "submit": 48}, "objects": {"": [[8, 0, 0, "-", "lmflow"]], "lmflow": [[8, 1, 1, "", "__version__"], [5, 0, 0, "-", "args"], [7, 0, 0, "-", "datasets"], [8, 1, 1, "", "internal_version"], [15, 0, 0, "-", "models"], [26, 0, 0, "-", "pipeline"], [37, 0, 0, "-", "utils"], [38, 0, 0, "-", "version"]], "lmflow.args": [[5, 2, 1, "", "AutoArguments"], [5, 2, 1, "", "BenchmarkingArguments"], [5, 2, 1, "", "DatasetArguments"], [5, 2, 1, "", "EvaluatorArguments"], [5, 2, 1, "", "FinetunerArguments"], [5, 2, 1, "", "InferencerArguments"], [5, 1, 1, "", "MODEL_CONFIG_CLASSES"], [5, 1, 1, "", "MODEL_TYPES"], [5, 2, 1, "", "ModelArguments"], [5, 1, 1, "", "PIPELINE_ARGUMENT_MAPPING"], [5, 2, 1, "", "RaftAlignerArguments"]], "lmflow.args.AutoArguments": [[5, 3, 1, "", "get_pipeline_args_class"]], "lmflow.args.BenchmarkingArguments": [[5, 4, 1, "", "dataset_name"], [5, 4, 1, "", "lm_evaluation_metric"]], "lmflow.args.DatasetArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "", "block_size"], [5, 4, 1, "", "customized_cache_dir"], [5, 4, 1, "", "dataset_config_name"], [5, 4, 1, "", "dataset_name"], [5, 4, 1, "", "dataset_path"], [5, 4, 1, "", "disable_group_texts"], [5, 4, 1, "", "group_texts_batch_size"], [5, 4, 1, "", "is_custom_dataset"], [5, 4, 1, "", "keep_linebreaks"], [5, 4, 1, "", "max_eval_samples"], [5, 4, 1, "", "max_train_samples"], [5, 4, 1, "", "overwrite_cache"], [5, 4, 1, "", "preprocessing_num_workers"], [5, 4, 1, "", "streaming"], [5, 4, 1, "", "test_file"], [5, 4, 1, "", "train_file"], [5, 4, 1, "", "validation_file"], [5, 4, 1, "", "validation_split_percentage"]], "lmflow.args.EvaluatorArguments": [[5, 4, 1, "", "answer_type"], [5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "evaluate_block_size"], [5, 4, 1, "", "inference_batch_size_per_device"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "max_new_tokens"], [5, 4, 1, "", "metric"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "output_dir"], [5, 4, 1, "", "prompt_structure"], [5, 4, 1, "", "random_seed"], [5, 4, 1, "", "random_shuffle"], [5, 4, 1, "", "repetition_penalty"], [5, 4, 1, "", "temperature"], [5, 4, 1, "", "use_accelerator_for_evaluator"], [5, 4, 1, "", "use_wandb"]], "lmflow.args.FinetunerArguments": [[5, 4, 1, "", "eval_dataset_path"]], "lmflow.args.InferencerArguments": [[5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "device"], [5, 4, 1, "", "do_sample"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "max_new_tokens"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "random_seed"], [5, 4, 1, "", "repetition_penalty"], [5, 4, 1, "", "temperature"]], "lmflow.args.ModelArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "id0", "arch_type"], [5, 4, 1, "", "cache_dir"], [5, 4, 1, "", "config_name"], [5, 4, 1, "", "config_overrides"], [5, 4, 1, "", "lora_alpha"], [5, 4, 1, "", "lora_dropout"], [5, 4, 1, "", "lora_model_path"], [5, 4, 1, "", "lora_r"], [5, 4, 1, "", "lora_target_modules"], [5, 4, 1, "", "model_name_or_path"], [5, 4, 1, "", "model_revision"], [5, 4, 1, "", "model_type"], [5, 4, 1, "", "save_aggregated_lora"], [5, 4, 1, "", "tokenizer_name"], [5, 4, 1, "", "torch_dtype"], [5, 4, 1, "", "use_auth_token"], [5, 4, 1, "", "use_fast_tokenizer"], [5, 4, 1, "", "use_flash_attention"], [5, 4, 1, "", "use_int8"], [5, 4, 1, "", "use_lora"], [5, 4, 1, "", "use_ram_optimized_load"]], "lmflow.args.RaftAlignerArguments": [[5, 4, 1, "", "collection_strategy"], [5, 4, 1, "", "inference_batch_size_per_device"], [5, 4, 1, "", "num_raft_iteration"], [5, 4, 1, "", "output_max_length"], [5, 4, 1, "", "output_min_length"], [5, 4, 1, "", "output_reward_path"], [5, 4, 1, "", "raft_batch_size"], [5, 4, 1, "", "top_reward_percentage"]], "lmflow.datasets": [[7, 2, 1, "", "Dataset"], [6, 0, 0, "-", "dataset"]], "lmflow.datasets.Dataset": [[7, 3, 1, "", "_check_data_format"], [7, 3, 1, "", "create_from_dict"], [7, 3, 1, "", "from_dict"], [7, 3, 1, "", "get_backend"], [7, 3, 1, "", "get_backend_dataset"], [7, 3, 1, "", "get_data_args"], [7, 3, 1, "", "get_fingerprint"], [7, 3, 1, "", "get_type"], [7, 3, 1, "", "map"], [7, 3, 1, "", "to_dict"]], "lmflow.datasets.dataset": [[6, 1, 1, "", "DATASET_TYPES"], [6, 2, 1, "", "Dataset"], [6, 1, 1, "", "KEY_INSTANCES"], [6, 1, 1, "", "KEY_TYPE"]], "lmflow.datasets.dataset.Dataset": [[6, 3, 1, "", "_check_data_format"], [6, 3, 1, "", "create_from_dict"], [6, 3, 1, "", "from_dict"], [6, 3, 1, "", "get_backend"], [6, 3, 1, "", "get_backend_dataset"], [6, 3, 1, "", "get_data_args"], [6, 3, 1, "", "get_fingerprint"], [6, 3, 1, "", "get_type"], [6, 3, 1, "", "map"], [6, 3, 1, "", "to_dict"]], "lmflow.models": [[9, 0, 0, "-", "auto_model"], [10, 0, 0, "-", "base_model"], [11, 0, 0, "-", "decoder_model"], [12, 0, 0, "-", "encoder_decoder_model"], [13, 0, 0, "-", "hf_decoder_model"], [14, 0, 0, "-", "hf_encoder_decoder_model"], [16, 0, 0, "-", "interfaces"], [18, 0, 0, "-", "regression_model"], [19, 0, 0, "-", "text_regression_model"]], "lmflow.models.auto_model": [[9, 2, 1, "", "AutoModel"]], "lmflow.models.auto_model.AutoModel": [[9, 3, 1, "", "get_model"]], "lmflow.models.base_model": [[10, 2, 1, "", "BaseModel"]], "lmflow.models.decoder_model": [[11, 2, 1, "", "DecoderModel"]], "lmflow.models.encoder_decoder_model": [[12, 2, 1, "", "EncoderDecoderModel"]], "lmflow.models.hf_decoder_model": [[13, 2, 1, "", "HFDecoderModel"], [13, 1, 1, "", "MODELS_SUPPORT_FLASH_ATTENTION"], [13, 1, 1, "", "logger"]], "lmflow.models.hf_decoder_model.HFDecoderModel": [[13, 3, 1, "", "decode"], [13, 3, 1, "", "encode"], [13, 3, 1, "", "get_backend_model"], [13, 3, 1, "", "get_max_length"], [13, 3, 1, "", "get_tokenizer"], [13, 3, 1, "", "inference"], [13, 3, 1, "", "merge_lora_weights"], [13, 3, 1, "", "save"], [13, 3, 1, "", "tokenize"]], "lmflow.models.hf_encoder_decoder_model": [[14, 2, 1, "", "HFEncoderDecoderModel"], [14, 1, 1, "", "logger"]], "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel": [[14, 3, 1, "", "decode"], [14, 3, 1, "", "encode"], [14, 3, 1, "", "get_backend_model"], [14, 3, 1, "", "get_max_length"], [14, 3, 1, "", "get_tokenizer"], [14, 3, 1, "", "inference"], [14, 3, 1, "", "merge_lora_weights"], [14, 3, 1, "", "save"], [14, 3, 1, "", "tokenize"]], "lmflow.models.interfaces": [[17, 0, 0, "-", "tunable"]], "lmflow.models.interfaces.tunable": [[17, 2, 1, "", "Tunable"]], "lmflow.models.regression_model": [[18, 2, 1, "", "RegressionModel"]], "lmflow.models.text_regression_model": [[19, 2, 1, "", "TextRegressionModel"]], "lmflow.models.text_regression_model.TextRegressionModel": [[19, 3, 1, "", "inference"], [19, 3, 1, "", "register_inference_function"]], "lmflow.pipeline": [[20, 0, 0, "-", "auto_pipeline"], [21, 0, 0, "-", "base_aligner"], [22, 0, 0, "-", "base_pipeline"], [23, 0, 0, "-", "base_tuner"], [24, 0, 0, "-", "evaluator"], [25, 0, 0, "-", "finetuner"], [27, 0, 0, "-", "inferencer"], [28, 0, 0, "-", "raft_aligner"], [29, 0, 0, "-", "utils"]], "lmflow.pipeline.auto_pipeline": [[20, 2, 1, "", "AutoPipeline"], [20, 1, 1, "", "PIPELINE_MAPPING"]], "lmflow.pipeline.auto_pipeline.AutoPipeline": [[20, 3, 1, "", "get_pipeline"]], "lmflow.pipeline.base_aligner": [[21, 2, 1, "", "BaseAligner"]], "lmflow.pipeline.base_aligner.BaseAligner": [[21, 3, 1, "", "_check_if_alignable"], [21, 3, 1, "", "align"]], "lmflow.pipeline.base_pipeline": [[22, 2, 1, "", "BasePipeline"]], "lmflow.pipeline.base_tuner": [[23, 2, 1, "", "BaseTuner"]], "lmflow.pipeline.base_tuner.BaseTuner": [[23, 3, 1, "", "_check_if_tunable"], [23, 3, 1, "", "tune"]], "lmflow.pipeline.evaluator": [[24, 2, 1, "", "Evaluator"]], "lmflow.pipeline.evaluator.Evaluator": [[24, 3, 1, "", "_evaluate_acc_with_accelerator"], [24, 3, 1, "", "_evaluate_acc_with_deepspeed"], [24, 3, 1, "", "_evaluate_nll"], [24, 3, 1, "", "_evaluate_ppl"], [24, 3, 1, "", "_match"], [24, 3, 1, "", "create_dataloader"], [24, 3, 1, "", "evaluate"]], "lmflow.pipeline.finetuner": [[25, 2, 1, "", "Finetuner"], [25, 1, 1, "", "logger"]], "lmflow.pipeline.finetuner.Finetuner": [[25, 3, 1, "", "group_text"], [25, 3, 1, "", "tune"]], "lmflow.pipeline.inferencer": [[27, 2, 1, "", "Inferencer"], [27, 5, 1, "", "rstrip_partial_utf8"]], "lmflow.pipeline.inferencer.Inferencer": [[27, 3, 1, "", "create_dataloader"], [27, 3, 1, "", "inference"], [27, 3, 1, "", "stream_inference"]], "lmflow.pipeline.raft_aligner": [[28, 2, 1, "", "RaftAligner"], [28, 1, 1, "", "logger"]], "lmflow.pipeline.raft_aligner.RaftAligner": [[28, 3, 1, "", "_clean_text"], [28, 3, 1, "", "_discard_sample"], [28, 3, 1, "", "_get_batch_dataset_local"], [28, 3, 1, "", "_get_batch_dataset_top"], [28, 3, 1, "", "_initialize_trainer"], [28, 3, 1, "", "_load_dataset"], [28, 3, 1, "", "_load_input_dataset"], [28, 3, 1, "", "align"]], "lmflow.pipeline.utils": [[30, 0, 0, "-", "peft_trainer"], [31, 0, 0, "-", "raft_trainer"]], "lmflow.pipeline.utils.peft_trainer": [[30, 2, 1, "", "PeftSavingCallback"], [30, 2, 1, "", "PeftTrainer"]], "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback": [[30, 3, 1, "", "_save"], [30, 3, 1, "", "on_epoch_end"], [30, 3, 1, "", "on_save"], [30, 3, 1, "", "on_train_end"]], "lmflow.pipeline.utils.peft_trainer.PeftTrainer": [[30, 3, 1, "", "_save_checkpoint"]], "lmflow.pipeline.utils.raft_trainer": [[31, 1, 1, "", "DEFAULT_CALLBACKS"], [31, 1, 1, "id0", "DEFAULT_PROGRESS_CALLBACK"], [31, 1, 1, "", "IS_SAGEMAKER_MP_POST_1_10"], [31, 1, 1, "", "OPTIMIZER_NAME"], [31, 2, 1, "", "RaftTrainer"], [31, 1, 1, "", "SCALER_NAME"], [31, 1, 1, "", "SCHEDULER_NAME"], [31, 1, 1, "", "TRAINER_STATE_NAME"], [31, 1, 1, "", "TRAINING_ARGS_NAME"], [31, 1, 1, "", "_is_native_cpu_amp_available"], [31, 1, 1, "", "logger"], [31, 1, 1, "", "skip_first_batches"]], "lmflow.pipeline.utils.raft_trainer.RaftTrainer": [[31, 3, 1, "", "_add_sm_patterns_to_gitignore"], [31, 3, 1, "", "_gather_and_numpify"], [31, 3, 1, "", "_get_collator_with_removed_columns"], [31, 3, 1, "", "_get_eval_sampler"], [31, 3, 1, "", "_get_output_dir"], [31, 3, 1, "", "_get_train_sampler"], [31, 3, 1, "", "_hp_search_setup"], [31, 3, 1, "", "_inner_training_loop"], [31, 3, 1, "", "_issue_warnings_after_load"], [31, 3, 1, "", "_load_best_model"], [31, 3, 1, "", "_load_from_checkpoint"], [31, 3, 1, "", "_load_optimizer_and_scheduler"], [31, 3, 1, "", "_load_rng_state"], [31, 3, 1, "", "_maybe_log_save_evaluate"], [31, 3, 1, "", "_move_model_to_device"], [31, 3, 1, "", "_nested_gather"], [31, 3, 1, "", "_one_train"], [31, 3, 1, "", "_pad_across_processes"], [31, 3, 1, "", "_prepare_input"], [31, 3, 1, "", "_prepare_inputs"], [31, 3, 1, "", "_push_from_checkpoint"], [31, 3, 1, "", "_remove_unused_columns"], [31, 3, 1, "", "_report_to_hp_search"], [31, 3, 1, "", "_rotate_checkpoints"], [31, 3, 1, "", "_save"], [31, 3, 1, "", "_save_checkpoint"], [31, 3, 1, "", "_save_tpu"], [31, 3, 1, "", "_set_signature_columns_if_needed"], [31, 3, 1, "", "_sorted_checkpoints"], [31, 3, 1, "", "_tune_save_checkpoint"], [31, 3, 1, "", "_wrap_model"], [31, 3, 1, "", "add_callback"], [31, 3, 1, "", "autocast_smart_context_manager"], [31, 3, 1, "", "call_model_init"], [31, 3, 1, "", "compute_loss"], [31, 3, 1, "", "compute_loss_context_manager"], [31, 3, 1, "", "create_model_card"], [31, 3, 1, "", "create_optimizer"], [31, 3, 1, "", "create_optimizer_and_scheduler"], [31, 3, 1, "", "create_scheduler"], [31, 3, 1, "", "evaluate"], [31, 3, 1, "", "evaluation_loop"], [31, 3, 1, "", "floating_point_ops"], [31, 3, 1, "", "get_eval_dataloader"], [31, 3, 1, "", "get_optimizer_cls_and_kwargs"], [31, 3, 1, "", "get_test_dataloader"], [31, 3, 1, "", "get_train_dataloader"], [31, 3, 1, "", "hyperparameter_search"], [31, 3, 1, "", "init_git_repo"], [31, 3, 1, "", "ipex_optimize_model"], [31, 3, 1, "", "is_local_process_zero"], [31, 3, 1, "", "is_world_process_zero"], [31, 3, 1, "", "log"], [31, 3, 1, "", "num_examples"], [31, 3, 1, "", "pop_callback"], [31, 3, 1, "", "predict"], [31, 3, 1, "", "prediction_loop"], [31, 3, 1, "", "prediction_step"], [31, 3, 1, "", "push_to_hub"], [31, 3, 1, "", "remove_callback"], [31, 3, 1, "", "save_model"], [31, 3, 1, "", "store_flos"], [31, 3, 1, "", "torch_jit_model_eval"], [31, 3, 1, "", "train"], [31, 3, 1, "", "training_step"]], "lmflow.utils": [[32, 0, 0, "-", "constants"], [33, 0, 0, "-", "data_utils"], [35, 0, 0, "-", "flash_attention"]], "lmflow.utils.constants": [[32, 1, 1, "", "DATASET_DESCRIPTION_MAP"], [32, 1, 1, "", "FLOAT_ONLY_DATASET_DESCRIPTION"], [32, 1, 1, "", "INSTANCE_FIELDS_MAP"], [32, 1, 1, "", "TEXT2TEXT_DATASET_DESCRIPTION"], [32, 1, 1, "", "TEXT2TEXT_DATASET_DETAILS"], [32, 1, 1, "", "TEXT2TEXT_DATASET_LONG_DESCRITION"], [32, 1, 1, "", "TEXT_ONLY_DATASET_DESCRIPTION"], [32, 1, 1, "", "TEXT_ONLY_DATASET_DETAILS"], [32, 1, 1, "", "TEXT_ONLY_DATASET_LONG_DESCRITION"]], "lmflow.utils.data_utils": [[33, 5, 1, "", "answer_extraction"], [33, 5, 1, "", "batchlize"], [33, 5, 1, "", "load_data"], [33, 5, 1, "", "set_random_seed"]], "lmflow.utils.flash_attention": [[34, 0, 0, "-", "gpt_neo_flash_attention"], [36, 0, 0, "-", "llama_flash_attention"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[34, 5, 1, "", "_attn"], [34, 5, 1, "", "forward"], [34, 5, 1, "", "replace_gpt_neo_attn_with_flash_attn"]], "lmflow.utils.flash_attention.llama_flash_attention": [[36, 5, 1, "", "_prepare_decoder_attention_mask"], [36, 5, 1, "", "forward"], [36, 5, 1, "", "replace_llama_attn_with_flash_attn"]], "lmflow.version": [[38, 1, 1, "", "__version__"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:method", "4": "py:attribute", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"]}, "titleterms": {"contributor": 0, "changelog": 1, "version": [1, 38], "0": 1, "1": [1, 42, 46, 47], "mar": 1, "28": 1, "2023": [1, 40], "about": 2, "lmflow": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 48], "arg": [3, 5], "api": 4, "refer": [4, 39], "modul": [5, 6, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 36, 38], "content": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 34, 36, 38, 48], "class": [5, 6, 7, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31], "attribut": [5, 6, 13, 14, 20, 25, 28, 31], "dataset": [6, 7, 41, 42, 46], "submodul": [7, 8, 15, 16, 26, 29, 35, 37], "packag": [7, 8], "subpackag": [8, 15, 26, 37], "model": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 46, 47], "auto_model": 9, "base_model": 10, "decoder_model": 11, "encoder_decoder_model": 12, "hf_decoder_model": 13, "hf_encoder_decoder_model": 14, "interfac": [16, 17], "tunabl": 17, "regression_model": 18, "text_regression_model": 19, "pipelin": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "auto_pipelin": 20, "base_align": 21, "base_pipelin": 22, "base_tun": 23, "evalu": [24, 39, 42, 44], "finetun": [25, 44, 45, 46, 47], "inferenc": 27, "function": [27, 33, 34, 36], "raft_align": 28, "util": [29, 30, 31, 32, 33, 34, 35, 36, 37], "peft_train": 30, "raft_train": 31, "constant": 32, "data_util": 33, "flash_attent": [34, 35, 36], "gpt_neo_flash_attent": 34, "llama_flash_attent": 36, "benchmark": [39, 42], "an": 39, "automat": 39, "framework": 39, "open": 39, "sourc": 39, "llm": 39, "introduct": [39, 46, 47, 48], "metric": 39, "chat": 39, "perform": 39, "commonsens": 39, "instruct": [39, 48], "follow": 39, "conclus": 39, "blog": 40, "format": 41, "gener": 41, "support": [41, 48], "detail": 41, "textonli": 41, "text2text": 41, "guid": 42, "nll": 42, "task": [42, 48], "set": 42, "setup": 42, "creat": 42, "your": 42, "file": 42, "registr": 42, "2": [42, 46, 47], "lm": 42, "checkpoint": [43, 48], "llama": 43, "exampl": [44, 46, 47], "data": 44, "prepar": 44, "infer": 44, "descript": 46, "reward": [46, 47], "supervis": [46, 47], "sft": [46, 47], "3": 46, "lora": 46, "merg": 46, "get": 46, "raft": 46, "align": 46, "algorithm": 46, "overview": 46, "hyper": 46, "paramet": 46, "step": 47, "featur": 48, "tune": 48, "instal": 48, "citat": 48, "disclaim": 48, "indic": 48, "tabl": 48}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Contributors": [[0, "contributors"]], "Changelog": [[1, "changelog"]], "Version 0.0.1 (Mar 28, 2023)": [[1, "version-0-0-1-mar-28-2023"]], "About": [[2, "about"]], "lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "API Reference": [[4, "api-reference"]], "Module Contents": [[5, "module-contents"], [6, "module-contents"], [9, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [27, "module-contents"], [28, "module-contents"], [30, "module-contents"], [31, "module-contents"], [32, "module-contents"], [33, "module-contents"], [34, "module-contents"], [36, "module-contents"], [38, "module-contents"]], "Classes": [[5, "classes"], [6, "classes"], [7, "classes"], [9, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [13, "classes"], [14, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [27, "classes"], [28, "classes"], [30, "classes"], [31, "classes"]], "Attributes": [[5, "attributes"], [6, "attributes"], [13, "attributes"], [14, "attributes"], [20, "attributes"], [25, "attributes"], [28, "attributes"], [31, "attributes"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "Submodules": [[7, "submodules"], [8, "submodules"], [15, "submodules"], [16, "submodules"], [26, "submodules"], [29, "submodules"], [35, "submodules"], [37, "submodules"]], "Package Contents": [[7, "package-contents"], [8, "package-contents"]], "lmflow": [[8, "module-lmflow"]], "Subpackages": [[8, "subpackages"], [15, "subpackages"], [26, "subpackages"], [37, "subpackages"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "lmflow.models.encoder_decoder_model": [[12, "module-lmflow.models.encoder_decoder_model"]], "lmflow.models.hf_decoder_model": [[13, "module-lmflow.models.hf_decoder_model"]], "lmflow.models.hf_encoder_decoder_model": [[14, "module-lmflow.models.hf_encoder_decoder_model"]], "lmflow.models": [[15, "module-lmflow.models"]], "lmflow.models.interfaces": [[16, "module-lmflow.models.interfaces"]], "lmflow.models.interfaces.tunable": [[17, "module-lmflow.models.interfaces.tunable"]], "lmflow.models.regression_model": [[18, "module-lmflow.models.regression_model"]], "lmflow.models.text_regression_model": [[19, "module-lmflow.models.text_regression_model"]], "lmflow.pipeline.auto_pipeline": [[20, "module-lmflow.pipeline.auto_pipeline"]], "lmflow.pipeline.base_aligner": [[21, "module-lmflow.pipeline.base_aligner"]], "lmflow.pipeline.base_pipeline": [[22, "module-lmflow.pipeline.base_pipeline"]], "lmflow.pipeline.base_tuner": [[23, "module-lmflow.pipeline.base_tuner"]], "lmflow.pipeline.evaluator": [[24, "module-lmflow.pipeline.evaluator"]], "lmflow.pipeline.finetuner": [[25, "module-lmflow.pipeline.finetuner"]], "lmflow.pipeline": [[26, "module-lmflow.pipeline"]], "lmflow.pipeline.inferencer": [[27, "module-lmflow.pipeline.inferencer"]], "Functions": [[27, "functions"], [33, "functions"], [34, "functions"], [36, "functions"]], "lmflow.pipeline.raft_aligner": [[28, "module-lmflow.pipeline.raft_aligner"]], "lmflow.pipeline.utils": [[29, "module-lmflow.pipeline.utils"]], "lmflow.pipeline.utils.peft_trainer": [[30, "module-lmflow.pipeline.utils.peft_trainer"]], "lmflow.pipeline.utils.raft_trainer": [[31, "module-lmflow.pipeline.utils.raft_trainer"]], "lmflow.utils.constants": [[32, "module-lmflow.utils.constants"]], "lmflow.utils.data_utils": [[33, "module-lmflow.utils.data_utils"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[34, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"]], "lmflow.utils.flash_attention": [[35, "module-lmflow.utils.flash_attention"]], "lmflow.utils.flash_attention.llama_flash_attention": [[36, "module-lmflow.utils.flash_attention.llama_flash_attention"]], "lmflow.utils": [[37, "module-lmflow.utils"]], "lmflow.version": [[38, "module-lmflow.version"]], "LMFlow Benchmark: An Automatic Evaluation Framework for Open-Source LLMs": [[39, "lmflow-benchmark-an-automatic-evaluation-framework-for-open-source-llms"]], "Introduction": [[39, "introduction"], [47, "introduction"], [48, "introduction"]], "Metric": [[39, "metric"]], "Chat Performance": [[39, "chat-performance"]], "CommonSense Performance": [[39, "commonsense-performance"]], "Instruction Following": [[39, "instruction-following"]], "Conclusion": [[39, "conclusion"]], "References": [[39, "references"]], "Blogs": [[40, "blogs"]], "2023": [[40, "id1"]], "Dataset": [[41, "dataset"]], "Dataset Format in General": [[41, "dataset-format-in-general"]], "Supported Dataset and Detailed Formats": [[41, "supported-dataset-and-detailed-formats"]], "TextOnly": [[41, "textonly"]], "Text2Text": [[41, "text2text"]], "LMFlow Benchmark Guide": [[42, "lmflow-benchmark-guide"]], "1. NLL Task Setting": [[42, "nll-task-setting"]], "Setup": [[42, "setup"]], "Create Your Task Dataset File": [[42, "create-your-task-dataset-file"]], "Task Registration": [[42, "task-registration"]], "2. LM-Evaluation Task Setting": [[42, "lm-evaluation-task-setting"]], "Checkpoints": [[43, "checkpoints"], [48, "checkpoints"]], "LLaMA Checkpoint": [[43, "llama-checkpoint"]], "Examples": [[44, "examples"], [47, "examples"]], "Data preparation": [[44, "data-preparation"]], "Finetuning": [[44, "finetuning"]], "Inference": [[44, "inference"]], "Evaluation": [[44, "evaluation"]], "Finetune": [[45, "finetune"]], "1 Introduction": [[46, "introduction"]], "1.1 Dataset description": [[46, "dataset-description"]], "2 Reward Modeling": [[46, "reward-modeling"]], "2.1 Supervised Finetuning (SFT)": [[46, "supervised-finetuning-sft"]], "2.2 Reward Modeling": [[46, "id1"]], "2.3 LoRA Merge and Get Reward Model": [[46, "lora-merge-and-get-reward-model"]], "3 RAFT Alignment": [[46, "raft-alignment"]], "3.1 Algorithms Overview": [[46, "algorithms-overview"]], "3.2 Hyper-parameters": [[46, "hyper-parameters"]], "3.3 Examples": [[46, "examples"]], "3.3.1 SFT": [[46, "sft"]], "3.3.2 RAFT Alignment": [[46, "id2"]], "Reward Modeling": [[47, "reward-modeling"]], "Step 1 Supervised Finetuning (SFT)": [[47, "step-1-supervised-finetuning-sft"]], "Step 2 Reward Modeling": [[47, "step-2-reward-modeling"]], "LMFlow": [[48, "lmflow"]], "Features": [[48, "features"]], "Task Tuning": [[48, "task-tuning"]], "Instruction Tuning": [[48, "instruction-tuning"]], "Installation": [[48, "installation"]], "Content": [[48, "content"]], "Citation": [[48, "citation"]], "Disclaimer": [[48, "disclaimer"]], "Support": [[48, "support"]], "Indices and tables": [[48, "indices-and-tables"]]}, "indexentries": {"lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "module": [[3, "module-lmflow.args"], [5, "module-lmflow.args"], [6, "module-lmflow.datasets.dataset"], [7, "module-lmflow.datasets"], [8, "module-lmflow"], [9, "module-lmflow.models.auto_model"], [10, "module-lmflow.models.base_model"], [11, "module-lmflow.models.decoder_model"], [12, "module-lmflow.models.encoder_decoder_model"], [13, "module-lmflow.models.hf_decoder_model"], [14, "module-lmflow.models.hf_encoder_decoder_model"], [15, "module-lmflow.models"], [16, "module-lmflow.models.interfaces"], [17, "module-lmflow.models.interfaces.tunable"], [18, "module-lmflow.models.regression_model"], [19, "module-lmflow.models.text_regression_model"], [20, "module-lmflow.pipeline.auto_pipeline"], [21, "module-lmflow.pipeline.base_aligner"], [22, "module-lmflow.pipeline.base_pipeline"], [23, "module-lmflow.pipeline.base_tuner"], [24, "module-lmflow.pipeline.evaluator"], [25, "module-lmflow.pipeline.finetuner"], [26, "module-lmflow.pipeline"], [27, "module-lmflow.pipeline.inferencer"], [28, "module-lmflow.pipeline.raft_aligner"], [29, "module-lmflow.pipeline.utils"], [30, "module-lmflow.pipeline.utils.peft_trainer"], [31, "module-lmflow.pipeline.utils.raft_trainer"], [32, "module-lmflow.utils.constants"], [33, "module-lmflow.utils.data_utils"], [34, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"], [35, "module-lmflow.utils.flash_attention"], [36, "module-lmflow.utils.flash_attention.llama_flash_attention"], [37, "module-lmflow.utils"], [38, "module-lmflow.version"]], "autoarguments (class in lmflow.args)": [[5, "lmflow.args.AutoArguments"]], "benchmarkingarguments (class in lmflow.args)": [[5, "lmflow.args.BenchmarkingArguments"]], "datasetarguments (class in lmflow.args)": [[5, "lmflow.args.DatasetArguments"]], "evaluatorarguments (class in lmflow.args)": [[5, "lmflow.args.EvaluatorArguments"]], "finetunerarguments (class in lmflow.args)": [[5, "lmflow.args.FinetunerArguments"]], "inferencerarguments (class in lmflow.args)": [[5, "lmflow.args.InferencerArguments"]], "model_config_classes (in module lmflow.args)": [[5, "lmflow.args.MODEL_CONFIG_CLASSES"]], "model_types (in module lmflow.args)": [[5, "lmflow.args.MODEL_TYPES"]], "modelarguments (class in lmflow.args)": [[5, "lmflow.args.ModelArguments"]], "pipeline_argument_mapping (in module lmflow.args)": [[5, "lmflow.args.PIPELINE_ARGUMENT_MAPPING"]], "raftalignerarguments (class in lmflow.args)": [[5, "lmflow.args.RaftAlignerArguments"]], "__post_init__() (lmflow.args.datasetarguments method)": [[5, "lmflow.args.DatasetArguments.__post_init__"]], "__post_init__() (lmflow.args.modelarguments method)": [[5, "lmflow.args.ModelArguments.__post_init__"]], "answer_type (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.answer_type"]], "arch_type (lmflow.args.modelarguments attribute)": [[5, "id0"], [5, "lmflow.args.ModelArguments.arch_type"]], "block_size (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.block_size"]], "cache_dir (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.cache_dir"]], "collection_strategy (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.collection_strategy"]], "config_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_name"]], "config_overrides (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_overrides"]], "customized_cache_dir (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.customized_cache_dir"]], "dataset_config_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_config_name"]], "dataset_name (lmflow.args.benchmarkingarguments attribute)": [[5, "lmflow.args.BenchmarkingArguments.dataset_name"]], "dataset_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_name"]], "dataset_path (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_path"]], "deepspeed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.deepspeed"]], "deepspeed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.deepspeed"]], "device (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.device"]], "disable_group_texts (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.disable_group_texts"]], "do_sample (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.do_sample"]], "eval_dataset_path (lmflow.args.finetunerarguments attribute)": [[5, "lmflow.args.FinetunerArguments.eval_dataset_path"]], "evaluate_block_size (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.evaluate_block_size"]], "get_pipeline_args_class() (lmflow.args.autoarguments method)": [[5, "lmflow.args.AutoArguments.get_pipeline_args_class"]], "group_texts_batch_size (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.group_texts_batch_size"]], "inference_batch_size_per_device (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.inference_batch_size_per_device"]], "inference_batch_size_per_device (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.inference_batch_size_per_device"]], "is_custom_dataset (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.is_custom_dataset"]], "keep_linebreaks (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.keep_linebreaks"]], "lm_evaluation_metric (lmflow.args.benchmarkingarguments attribute)": [[5, "lmflow.args.BenchmarkingArguments.lm_evaluation_metric"]], "local_rank (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.local_rank"]], "local_rank (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.local_rank"]], "lora_alpha (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_alpha"]], "lora_dropout (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_dropout"]], "lora_model_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_model_path"]], "lora_r (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_r"]], "lora_target_modules (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_target_modules"]], "max_eval_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_eval_samples"]], "max_new_tokens (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.max_new_tokens"]], "max_new_tokens (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.max_new_tokens"]], "max_train_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_train_samples"]], "metric (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.metric"]], "mixed_precision (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.mixed_precision"]], "mixed_precision (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.mixed_precision"]], "model_name_or_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_name_or_path"]], "model_revision (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_revision"]], "model_type (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_type"]], "num_raft_iteration (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.num_raft_iteration"]], "output_dir (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.output_dir"]], "output_max_length (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_max_length"]], "output_min_length (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_min_length"]], "output_reward_path (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_reward_path"]], "overwrite_cache (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.overwrite_cache"]], "preprocessing_num_workers (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.preprocessing_num_workers"]], "prompt_structure (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.prompt_structure"]], "raft_batch_size (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.raft_batch_size"]], "random_seed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_seed"]], "random_seed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.random_seed"]], "random_shuffle (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_shuffle"]], "repetition_penalty (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.repetition_penalty"]], "repetition_penalty (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.repetition_penalty"]], "save_aggregated_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.save_aggregated_lora"]], "streaming (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.streaming"]], "temperature (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.temperature"]], "temperature (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.temperature"]], "test_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.test_file"]], "tokenizer_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.tokenizer_name"]], "top_reward_percentage (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.top_reward_percentage"]], "torch_dtype (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.torch_dtype"]], "train_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.train_file"]], "use_accelerator_for_evaluator (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.use_accelerator_for_evaluator"]], "use_auth_token (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_auth_token"]], "use_fast_tokenizer (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_fast_tokenizer"]], "use_flash_attention (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_flash_attention"]], "use_int8 (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_int8"]], "use_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_lora"]], "use_ram_optimized_load (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_ram_optimized_load"]], "use_wandb (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.use_wandb"]], "validation_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_file"]], "validation_split_percentage (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_split_percentage"]], "dataset_types (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.DATASET_TYPES"]], "dataset (class in lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.Dataset"]], "key_instances (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_INSTANCES"]], "key_type (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_TYPE"]], "_check_data_format() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset._check_data_format"]], "create_from_dict() (lmflow.datasets.dataset.dataset class method)": [[6, "lmflow.datasets.dataset.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_data_args"]], "get_fingerprint() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_fingerprint"]], "get_type() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_type"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "map() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.map"]], "to_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.to_dict"]], "dataset (class in lmflow.datasets)": [[7, "lmflow.datasets.Dataset"]], "_check_data_format() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset._check_data_format"]], "create_from_dict() (lmflow.datasets.dataset class method)": [[7, "lmflow.datasets.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_data_args"]], "get_fingerprint() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_fingerprint"]], "get_type() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_type"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "map() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.map"]], "to_dict() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.to_dict"]], "__version__ (in module lmflow)": [[8, "lmflow.__version__"]], "internal_version (in module lmflow)": [[8, "lmflow.internal_version"]], "lmflow": [[8, "module-lmflow"]], "automodel (class in lmflow.models.auto_model)": [[9, "lmflow.models.auto_model.AutoModel"]], "get_model() (lmflow.models.auto_model.automodel class method)": [[9, "lmflow.models.auto_model.AutoModel.get_model"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "basemodel (class in lmflow.models.base_model)": [[10, "lmflow.models.base_model.BaseModel"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "decodermodel (class in lmflow.models.decoder_model)": [[11, "lmflow.models.decoder_model.DecoderModel"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "encoderdecodermodel (class in lmflow.models.encoder_decoder_model)": [[12, "lmflow.models.encoder_decoder_model.EncoderDecoderModel"]], "lmflow.models.encoder_decoder_model": [[12, "module-lmflow.models.encoder_decoder_model"]], "hfdecodermodel (class in lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel"]], "models_support_flash_attention (in module lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.MODELS_SUPPORT_FLASH_ATTENTION"]], "decode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.decode"]], "encode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_max_length"]], "get_tokenizer() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.inference"]], "lmflow.models.hf_decoder_model": [[13, "module-lmflow.models.hf_decoder_model"]], "logger (in module lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.save"]], "tokenize() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.tokenize"]], "hfencoderdecodermodel (class in lmflow.models.hf_encoder_decoder_model)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel"]], "decode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.decode"]], "encode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_max_length"]], "get_tokenizer() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.inference"]], "lmflow.models.hf_encoder_decoder_model": [[14, "module-lmflow.models.hf_encoder_decoder_model"]], "logger (in module lmflow.models.hf_encoder_decoder_model)": [[14, "lmflow.models.hf_encoder_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.save"]], "tokenize() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.tokenize"]], "lmflow.models": [[15, "module-lmflow.models"]], "lmflow.models.interfaces": [[16, "module-lmflow.models.interfaces"]], "tunable (class in lmflow.models.interfaces.tunable)": [[17, "lmflow.models.interfaces.tunable.Tunable"]], "lmflow.models.interfaces.tunable": [[17, "module-lmflow.models.interfaces.tunable"]], "regressionmodel (class in lmflow.models.regression_model)": [[18, "lmflow.models.regression_model.RegressionModel"]], "lmflow.models.regression_model": [[18, "module-lmflow.models.regression_model"]], "textregressionmodel (class in lmflow.models.text_regression_model)": [[19, "lmflow.models.text_regression_model.TextRegressionModel"]], "inference() (lmflow.models.text_regression_model.textregressionmodel method)": [[19, "lmflow.models.text_regression_model.TextRegressionModel.inference"]], "lmflow.models.text_regression_model": [[19, "module-lmflow.models.text_regression_model"]], "register_inference_function() (lmflow.models.text_regression_model.textregressionmodel method)": [[19, "lmflow.models.text_regression_model.TextRegressionModel.register_inference_function"]], "autopipeline (class in lmflow.pipeline.auto_pipeline)": [[20, "lmflow.pipeline.auto_pipeline.AutoPipeline"]], "pipeline_mapping (in module lmflow.pipeline.auto_pipeline)": [[20, "lmflow.pipeline.auto_pipeline.PIPELINE_MAPPING"]], "get_pipeline() (lmflow.pipeline.auto_pipeline.autopipeline class method)": [[20, "lmflow.pipeline.auto_pipeline.AutoPipeline.get_pipeline"]], "lmflow.pipeline.auto_pipeline": [[20, "module-lmflow.pipeline.auto_pipeline"]], "basealigner (class in lmflow.pipeline.base_aligner)": [[21, "lmflow.pipeline.base_aligner.BaseAligner"]], "_check_if_alignable() (lmflow.pipeline.base_aligner.basealigner method)": [[21, "lmflow.pipeline.base_aligner.BaseAligner._check_if_alignable"]], "align() (lmflow.pipeline.base_aligner.basealigner method)": [[21, "lmflow.pipeline.base_aligner.BaseAligner.align"]], "lmflow.pipeline.base_aligner": [[21, "module-lmflow.pipeline.base_aligner"]], "basepipeline (class in lmflow.pipeline.base_pipeline)": [[22, "lmflow.pipeline.base_pipeline.BasePipeline"]], "lmflow.pipeline.base_pipeline": [[22, "module-lmflow.pipeline.base_pipeline"]], "basetuner (class in lmflow.pipeline.base_tuner)": [[23, "lmflow.pipeline.base_tuner.BaseTuner"]], "_check_if_tunable() (lmflow.pipeline.base_tuner.basetuner method)": [[23, "lmflow.pipeline.base_tuner.BaseTuner._check_if_tunable"]], "lmflow.pipeline.base_tuner": [[23, "module-lmflow.pipeline.base_tuner"]], "tune() (lmflow.pipeline.base_tuner.basetuner method)": [[23, "lmflow.pipeline.base_tuner.BaseTuner.tune"]], "evaluator (class in lmflow.pipeline.evaluator)": [[24, "lmflow.pipeline.evaluator.Evaluator"]], "_evaluate_acc_with_accelerator() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc_with_accelerator"]], "_evaluate_acc_with_deepspeed() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc_with_deepspeed"]], "_evaluate_nll() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_nll"]], "_evaluate_ppl() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_ppl"]], "_match() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._match"]], "create_dataloader() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator.create_dataloader"]], "evaluate() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator.evaluate"]], "lmflow.pipeline.evaluator": [[24, "module-lmflow.pipeline.evaluator"]], "finetuner (class in lmflow.pipeline.finetuner)": [[25, "lmflow.pipeline.finetuner.Finetuner"]], "group_text() (lmflow.pipeline.finetuner.finetuner method)": [[25, "lmflow.pipeline.finetuner.Finetuner.group_text"]], "lmflow.pipeline.finetuner": [[25, "module-lmflow.pipeline.finetuner"]], "logger (in module lmflow.pipeline.finetuner)": [[25, "lmflow.pipeline.finetuner.logger"]], "tune() (lmflow.pipeline.finetuner.finetuner method)": [[25, "lmflow.pipeline.finetuner.Finetuner.tune"]], "lmflow.pipeline": [[26, "module-lmflow.pipeline"]], "inferencer (class in lmflow.pipeline.inferencer)": [[27, "lmflow.pipeline.inferencer.Inferencer"]], "create_dataloader() (lmflow.pipeline.inferencer.inferencer method)": [[27, "lmflow.pipeline.inferencer.Inferencer.create_dataloader"]], "inference() (lmflow.pipeline.inferencer.inferencer method)": [[27, "lmflow.pipeline.inferencer.Inferencer.inference"]], "lmflow.pipeline.inferencer": [[27, "module-lmflow.pipeline.inferencer"]], "rstrip_partial_utf8() (in module lmflow.pipeline.inferencer)": [[27, "lmflow.pipeline.inferencer.rstrip_partial_utf8"]], "stream_inference() (lmflow.pipeline.inferencer.inferencer method)": [[27, "lmflow.pipeline.inferencer.Inferencer.stream_inference"]], "raftaligner (class in lmflow.pipeline.raft_aligner)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner"]], "_clean_text() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._clean_text"]], "_discard_sample() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._discard_sample"]], "_get_batch_dataset_local() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._get_batch_dataset_local"]], "_get_batch_dataset_top() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._get_batch_dataset_top"]], "_initialize_trainer() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._initialize_trainer"]], "_load_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._load_dataset"]], "_load_input_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._load_input_dataset"]], "align() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner.align"]], "lmflow.pipeline.raft_aligner": [[28, "module-lmflow.pipeline.raft_aligner"]], "logger (in module lmflow.pipeline.raft_aligner)": [[28, "lmflow.pipeline.raft_aligner.logger"]], "lmflow.pipeline.utils": [[29, "module-lmflow.pipeline.utils"]], "peftsavingcallback (class in lmflow.pipeline.utils.peft_trainer)": [[30, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback"]], "pefttrainer (class in lmflow.pipeline.utils.peft_trainer)": [[30, "lmflow.pipeline.utils.peft_trainer.PeftTrainer"]], "_save() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[30, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback._save"]], "_save_checkpoint() (lmflow.pipeline.utils.peft_trainer.pefttrainer method)": [[30, "lmflow.pipeline.utils.peft_trainer.PeftTrainer._save_checkpoint"]], "lmflow.pipeline.utils.peft_trainer": [[30, "module-lmflow.pipeline.utils.peft_trainer"]], "on_epoch_end() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[30, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback.on_epoch_end"]], "on_save() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[30, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback.on_save"]], "on_train_end() (lmflow.pipeline.utils.peft_trainer.peftsavingcallback method)": [[30, "lmflow.pipeline.utils.peft_trainer.PeftSavingCallback.on_train_end"]], "default_callbacks (in module lmflow.pipeline.utils.raft_trainer)": [[31, "lmflow.pipeline.utils.raft_trainer.DEFAULT_CALLBACKS"]], "default_progress_callback (in module lmflow.pipeline.utils.raft_trainer)": [[31, "id0"], [31, "lmflow.pipeline.utils.raft_trainer.DEFAULT_PROGRESS_CALLBACK"]], "is_sagemaker_mp_post_1_10 (in module lmflow.pipeline.utils.raft_trainer)": [[31, "lmflow.pipeline.utils.raft_trainer.IS_SAGEMAKER_MP_POST_1_10"]], "optimizer_name (in module lmflow.pipeline.utils.raft_trainer)": [[31, "lmflow.pipeline.utils.raft_trainer.OPTIMIZER_NAME"]], "rafttrainer (class in lmflow.pipeline.utils.raft_trainer)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer"]], "scaler_name (in module lmflow.pipeline.utils.raft_trainer)": [[31, "lmflow.pipeline.utils.raft_trainer.SCALER_NAME"]], "scheduler_name (in module lmflow.pipeline.utils.raft_trainer)": [[31, "lmflow.pipeline.utils.raft_trainer.SCHEDULER_NAME"]], "trainer_state_name (in module lmflow.pipeline.utils.raft_trainer)": [[31, "lmflow.pipeline.utils.raft_trainer.TRAINER_STATE_NAME"]], "training_args_name (in module lmflow.pipeline.utils.raft_trainer)": [[31, "lmflow.pipeline.utils.raft_trainer.TRAINING_ARGS_NAME"]], "_add_sm_patterns_to_gitignore() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._add_sm_patterns_to_gitignore"]], "_gather_and_numpify() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._gather_and_numpify"]], "_get_collator_with_removed_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_collator_with_removed_columns"]], "_get_eval_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_eval_sampler"]], "_get_output_dir() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_output_dir"]], "_get_train_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_train_sampler"]], "_hp_search_setup() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._hp_search_setup"]], "_inner_training_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._inner_training_loop"]], "_is_native_cpu_amp_available (in module lmflow.pipeline.utils.raft_trainer)": [[31, "lmflow.pipeline.utils.raft_trainer._is_native_cpu_amp_available"]], "_issue_warnings_after_load() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._issue_warnings_after_load"]], "_load_best_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_best_model"]], "_load_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_from_checkpoint"]], "_load_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_optimizer_and_scheduler"]], "_load_rng_state() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_rng_state"]], "_maybe_log_save_evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._maybe_log_save_evaluate"]], "_move_model_to_device() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._move_model_to_device"]], "_nested_gather() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._nested_gather"]], "_one_train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._one_train"]], "_pad_across_processes() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._pad_across_processes"]], "_prepare_input() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_input"]], "_prepare_inputs() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_inputs"]], "_push_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._push_from_checkpoint"]], "_remove_unused_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._remove_unused_columns"]], "_report_to_hp_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._report_to_hp_search"]], "_rotate_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._rotate_checkpoints"]], "_save() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save"]], "_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_checkpoint"]], "_save_tpu() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_tpu"]], "_set_signature_columns_if_needed() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._set_signature_columns_if_needed"]], "_sorted_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._sorted_checkpoints"]], "_tune_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._tune_save_checkpoint"]], "_wrap_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._wrap_model"]], "add_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.add_callback"]], "autocast_smart_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.autocast_smart_context_manager"]], "call_model_init() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.call_model_init"]], "compute_loss() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss"]], "compute_loss_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss_context_manager"]], "create_model_card() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_model_card"]], "create_optimizer() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer"]], "create_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer_and_scheduler"]], "create_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_scheduler"]], "evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluate"]], "evaluation_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluation_loop"]], "floating_point_ops() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.floating_point_ops"]], "get_eval_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_eval_dataloader"]], "get_optimizer_cls_and_kwargs() (lmflow.pipeline.utils.raft_trainer.rafttrainer static method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_optimizer_cls_and_kwargs"]], "get_test_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_test_dataloader"]], "get_train_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_train_dataloader"]], "hyperparameter_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.hyperparameter_search"]], "init_git_repo() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.init_git_repo"]], "ipex_optimize_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.ipex_optimize_model"]], "is_local_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_local_process_zero"]], "is_world_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_world_process_zero"]], "lmflow.pipeline.utils.raft_trainer": [[31, "module-lmflow.pipeline.utils.raft_trainer"]], "log() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.log"]], "logger (in module lmflow.pipeline.utils.raft_trainer)": [[31, "lmflow.pipeline.utils.raft_trainer.logger"]], "num_examples() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.num_examples"]], "pop_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.pop_callback"]], "predict() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.predict"]], "prediction_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_loop"]], "prediction_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_step"]], "push_to_hub() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.push_to_hub"]], "remove_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.remove_callback"]], "save_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.save_model"]], "skip_first_batches (in module lmflow.pipeline.utils.raft_trainer)": [[31, "lmflow.pipeline.utils.raft_trainer.skip_first_batches"]], "store_flos() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.store_flos"]], "torch_jit_model_eval() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.torch_jit_model_eval"]], "train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.train"]], "training_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[31, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.training_step"]], "dataset_description_map (in module lmflow.utils.constants)": [[32, "lmflow.utils.constants.DATASET_DESCRIPTION_MAP"]], "float_only_dataset_description (in module lmflow.utils.constants)": [[32, "lmflow.utils.constants.FLOAT_ONLY_DATASET_DESCRIPTION"]], "instance_fields_map (in module lmflow.utils.constants)": [[32, "lmflow.utils.constants.INSTANCE_FIELDS_MAP"]], "text2text_dataset_description (in module lmflow.utils.constants)": [[32, "lmflow.utils.constants.TEXT2TEXT_DATASET_DESCRIPTION"]], "text2text_dataset_details (in module lmflow.utils.constants)": [[32, "lmflow.utils.constants.TEXT2TEXT_DATASET_DETAILS"]], "text2text_dataset_long_descrition (in module lmflow.utils.constants)": [[32, "lmflow.utils.constants.TEXT2TEXT_DATASET_LONG_DESCRITION"]], "text_only_dataset_description (in module lmflow.utils.constants)": [[32, "lmflow.utils.constants.TEXT_ONLY_DATASET_DESCRIPTION"]], "text_only_dataset_details (in module lmflow.utils.constants)": [[32, "lmflow.utils.constants.TEXT_ONLY_DATASET_DETAILS"]], "text_only_dataset_long_descrition (in module lmflow.utils.constants)": [[32, "lmflow.utils.constants.TEXT_ONLY_DATASET_LONG_DESCRITION"]], "lmflow.utils.constants": [[32, "module-lmflow.utils.constants"]], "answer_extraction() (in module lmflow.utils.data_utils)": [[33, "lmflow.utils.data_utils.answer_extraction"]], "batchlize() (in module lmflow.utils.data_utils)": [[33, "lmflow.utils.data_utils.batchlize"]], "lmflow.utils.data_utils": [[33, "module-lmflow.utils.data_utils"]], "load_data() (in module lmflow.utils.data_utils)": [[33, "lmflow.utils.data_utils.load_data"]], "set_random_seed() (in module lmflow.utils.data_utils)": [[33, "lmflow.utils.data_utils.set_random_seed"]], "_attn() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[34, "lmflow.utils.flash_attention.gpt_neo_flash_attention._attn"]], "forward() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[34, "lmflow.utils.flash_attention.gpt_neo_flash_attention.forward"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[34, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"]], "replace_gpt_neo_attn_with_flash_attn() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[34, "lmflow.utils.flash_attention.gpt_neo_flash_attention.replace_gpt_neo_attn_with_flash_attn"]], "lmflow.utils.flash_attention": [[35, "module-lmflow.utils.flash_attention"]], "_prepare_decoder_attention_mask() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[36, "lmflow.utils.flash_attention.llama_flash_attention._prepare_decoder_attention_mask"]], "forward() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[36, "lmflow.utils.flash_attention.llama_flash_attention.forward"]], "lmflow.utils.flash_attention.llama_flash_attention": [[36, "module-lmflow.utils.flash_attention.llama_flash_attention"]], "replace_llama_attn_with_flash_attn() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[36, "lmflow.utils.flash_attention.llama_flash_attention.replace_llama_attn_with_flash_attn"]], "lmflow.utils": [[37, "module-lmflow.utils"]], "__version__ (in module lmflow.version)": [[38, "lmflow.version.__version__"]], "lmflow.version": [[38, "module-lmflow.version"]]}})